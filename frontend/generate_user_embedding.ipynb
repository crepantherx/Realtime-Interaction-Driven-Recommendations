{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T10:59:24.327192Z",
     "start_time": "2025-11-15T10:59:23.774846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import random, uuid, json\n",
    "from datetime import datetime\n",
    "\n",
    "# ================================================================\n",
    "# Config: global RNG & sizes\n",
    "# ================================================================\n",
    "DEFAULT_SEED = 123\n",
    "N_PROFILES = 10_000\n",
    "rng = random.Random(DEFAULT_SEED)\n",
    "\n",
    "# ================================================================\n",
    "# Taxonomies\n",
    "# ================================================================\n",
    "GENDERS = [\"Woman\", \"Man\", \"Non-binary\"]\n",
    "\n",
    "INTEREST_CLUSTERS = {\n",
    "    \"Active\": [\"Hiking\", \"Running\", \"Yoga\", \"Dancing\", \"Photography\"],\n",
    "    \"Arts\": [\"Art\", \"Theatre\", \"Poetry\", \"Movies\", \"Music\"],\n",
    "    \"Geek\": [\"Tech\", \"Gaming\", \"Startups\", \"Board Games\"],\n",
    "    \"Social\": [\"Foodie\", \"Travel\", \"Standup Comedy\", \"Volunteering\"],\n",
    "    \"Sports\": [\"Cricket\", \"Football\", \"Basketball\"],\n",
    "}\n",
    "ALL_INTERESTS = sorted({i for v in INTEREST_CLUSTERS.values() for i in v})\n",
    "\n",
    "# Name pools (extend as you like)\n",
    "FEMALE_FIRST = [\n",
    "    \"Aditi\",\"Aarohi\",\"Anaya\",\"Diya\",\"Isha\",\"Myra\",\"Sara\",\"Siya\",\"Tara\",\"Zara\",\n",
    "    \"Neha\",\"Priya\",\"Naina\",\"Rhea\",\"Meera\",\"Anika\",\"Kavya\",\"Ritu\",\"Pooja\",\"Sana\",\n",
    "    \"Anna\",\"Maria\",\"Sofia\",\"Emma\",\"Olivia\",\"Mia\",\"Aisha\",\"Fatima\",\"Yuna\",\"Mei\",\n",
    "    \"Camila\",\"Valentina\",\"Amara\",\"Zainab\",\"Helena\",\"Elena\",\"Giulia\",\"Lina\",\"Aya\"\n",
    "]\n",
    "MALE_FIRST = [\n",
    "    \"Aarav\",\"Vivaan\",\"Aditya\",\"Vihaan\",\"Arjun\",\"Sai\",\"Krishna\",\"Ishaan\",\"Rohan\",\"Kabir\",\n",
    "    \"Raghav\",\"Aman\",\"Rajat\",\"Varun\",\"Anil\",\"Rahul\",\"Aakash\",\"Nikhil\",\"Sandeep\",\"Yash\",\n",
    "    \"Liam\",\"Noah\",\"Lucas\",\"Mateo\",\"Ethan\",\"Leo\",\"Hiro\",\"Daichi\",\"Minjun\",\"Jae\",\n",
    "    \"Luis\",\"Diego\",\"Andre\",\"Omar\",\"Youssef\",\"Ali\",\"Marco\",\"Jonas\",\"Felix\",\"Tariq\"\n",
    "]\n",
    "UNISEX_FIRST = [\"Sam\",\"Dev\",\"Shiv\",\"Arya\",\"Sasha\",\"Riyaan\",\"Jai\",\"Ray\",\"Kiran\",\"Alex\",\"Charlie\",\"Noor\",\"Ariel\",\"Jordan\",\"Kai\"]\n",
    "\n",
    "# ================================================================\n",
    "# Geography: India tiers + global regions\n",
    "# Weights are rough, population-leaning proxies (tune freely)\n",
    "# ================================================================\n",
    "INDIA_TIERS = {\n",
    "    \"Tier-1\": [\n",
    "        (\"India\", \"Mumbai\", 10),\n",
    "        (\"India\", \"Delhi\", 10),\n",
    "        (\"India\", \"Bengaluru\", 9),\n",
    "        (\"India\", \"Hyderabad\", 8),\n",
    "        (\"India\", \"Chennai\", 7),\n",
    "        (\"India\", \"Kolkata\", 7),\n",
    "        (\"India\", \"Pune\", 6),\n",
    "        (\"India\", \"Ahmedabad\", 5),\n",
    "    ],\n",
    "    \"Tier-2\": [\n",
    "        (\"India\", \"Jaipur\", 4), (\"India\", \"Surat\", 4), (\"India\", \"Lucknow\", 4),\n",
    "        (\"India\", \"Kanpur\", 3), (\"India\", \"Nagpur\", 3), (\"India\", \"Indore\", 3),\n",
    "        (\"India\", \"Bhopal\", 3), (\"India\", \"Chandigarh\", 2), (\"India\", \"Kochi\", 2),\n",
    "        (\"India\", \"Coimbatore\", 2),\n",
    "    ],\n",
    "    \"Tier-3\": [\n",
    "        (\"India\", \"Patna\", 2), (\"India\", \"Guwahati\", 2), (\"India\", \"Visakhapatnam\", 2),\n",
    "        (\"India\", \"Vijayawada\", 2), (\"India\", \"Bhubaneswar\", 2), (\"India\", \"Thiruvananthapuram\", 2),\n",
    "        (\"India\", \"Vadodara\", 2), (\"India\", \"Nashik\", 2), (\"India\", \"Ludhiana\", 2), (\"India\", \"Rajkot\", 2),\n",
    "    ],\n",
    "}\n",
    "\n",
    "WORLD_REGIONS = {\n",
    "    \"South Asia (non-India)\": [\n",
    "        (\"Bangladesh\", \"Dhaka\", 8), (\"Bangladesh\", \"Chittagong\", 3),\n",
    "        (\"Pakistan\", \"Karachi\", 9), (\"Pakistan\", \"Lahore\", 6), (\"Pakistan\", \"Islamabad\", 2),\n",
    "        (\"Sri Lanka\", \"Colombo\", 2), (\"Nepal\", \"Kathmandu\", 2),\n",
    "    ],\n",
    "    \"East Asia\": [\n",
    "        (\"Japan\", \"Tokyo\", 10), (\"Japan\", \"Osaka\", 4),\n",
    "        (\"South Korea\", \"Seoul\", 8), (\"South Korea\", \"Busan\", 3),\n",
    "        (\"China\", \"Shanghai\", 10), (\"China\", \"Beijing\", 9), (\"China\", \"Shenzhen\", 7), (\"China\", \"Guangzhou\", 7),\n",
    "        (\"Taiwan\", \"Taipei\", 4), (\"Hong Kong\", \"Hong Kong\", 5),\n",
    "    ],\n",
    "    \"Southeast Asia\": [\n",
    "        (\"Singapore\", \"Singapore\", 6),\n",
    "        (\"Malaysia\", \"Kuala Lumpur\", 4),\n",
    "        (\"Thailand\", \"Bangkok\", 7),\n",
    "        (\"Indonesia\", \"Jakarta\", 9), (\"Vietnam\", \"Ho Chi Minh City\", 6), (\"Vietnam\", \"Hanoi\", 5),\n",
    "        (\"Philippines\", \"Manila\", 8),\n",
    "    ],\n",
    "    \"North America\": [\n",
    "        (\"USA\", \"New York\", 9), (\"USA\", \"Los Angeles\", 8), (\"USA\", \"Chicago\", 6),\n",
    "        (\"USA\", \"San Francisco\", 5), (\"USA\", \"Houston\", 5), (\"USA\", \"Miami\", 5),\n",
    "        (\"Canada\", \"Toronto\", 6), (\"Canada\", \"Vancouver\", 4), (\"Canada\", \"Montreal\", 4),\n",
    "        (\"Mexico\", \"Mexico City\", 9), (\"Mexico\", \"Guadalajara\", 4),\n",
    "    ],\n",
    "    \"Europe\": [\n",
    "        (\"UK\", \"London\", 9), (\"France\", \"Paris\", 8), (\"Germany\", \"Berlin\", 6),\n",
    "        (\"Spain\", \"Madrid\", 5), (\"Spain\", \"Barcelona\", 5),\n",
    "        (\"Italy\", \"Rome\", 5), (\"Italy\", \"Milan\", 4),\n",
    "        (\"Netherlands\", \"Amsterdam\", 4), (\"Austria\", \"Vienna\", 4), (\"Sweden\", \"Stockholm\", 3),\n",
    "    ],\n",
    "    \"MENA\": [\n",
    "        (\"UAE\", \"Dubai\", 7), (\"UAE\", \"Abu Dhabi\", 4),\n",
    "        (\"Saudi Arabia\", \"Riyadh\", 6), (\"Saudi Arabia\", \"Jeddah\", 5),\n",
    "        (\"Egypt\", \"Cairo\", 8), (\"Egypt\", \"Alexandria\", 4),\n",
    "        (\"Türkiye\", \"Istanbul\", 8), (\"Morocco\", \"Casablanca\", 4),\n",
    "    ],\n",
    "    \"Sub-Saharan Africa\": [\n",
    "        (\"Nigeria\", \"Lagos\", 9), (\"Nigeria\", \"Abuja\", 4),\n",
    "        (\"Kenya\", \"Nairobi\", 6), (\"Kenya\", \"Mombasa\", 3),\n",
    "        (\"Ghana\", \"Accra\", 4), (\"Ghana\", \"Kumasi\", 3),\n",
    "        (\"South Africa\", \"Johannesburg\", 5), (\"South Africa\", \"Cape Town\", 5), (\"South Africa\", \"Durban\", 3),\n",
    "        (\"Ethiopia\", \"Addis Ababa\", 5),\n",
    "    ],\n",
    "    \"Latin America\": [\n",
    "        (\"Brazil\", \"São Paulo\", 10), (\"Brazil\", \"Rio de Janeiro\", 7),\n",
    "        (\"Argentina\", \"Buenos Aires\", 8), (\"Chile\", \"Santiago\", 6),\n",
    "        (\"Peru\", \"Lima\", 7), (\"Colombia\", \"Bogotá\", 7), (\"Colombia\", \"Medellín\", 4),\n",
    "        (\"Ecuador\", \"Quito\", 3), (\"Uruguay\", \"Montevideo\", 3),\n",
    "    ],\n",
    "    \"Oceania\": [\n",
    "        (\"Australia\", \"Sydney\", 6), (\"Australia\", \"Melbourne\", 6),\n",
    "        (\"Australia\", \"Brisbane\", 3), (\"Australia\", \"Perth\", 3),\n",
    "        (\"New Zealand\", \"Auckland\", 3), (\"New Zealand\", \"Wellington\", 2),\n",
    "    ],\n",
    "}\n",
    "\n",
    "def build_city_table(include_india=True, india_tier_bias=(0.5, 0.35, 0.15)):\n",
    "    rows = []\n",
    "    if include_india:\n",
    "        tiers = [\"Tier-1\", \"Tier-2\", \"Tier-3\"]\n",
    "        tier_w = dict(zip(tiers, india_tier_bias))\n",
    "        for tier in tiers:\n",
    "            for country, city, w in INDIA_TIERS[tier]:\n",
    "                rows.append((\"South Asia\", country, city, w * (1 + 9 * tier_w[tier])))\n",
    "    for region, cities in WORLD_REGIONS.items():\n",
    "        for country, city, w in cities:\n",
    "            rows.append((region, country, city, w))\n",
    "    return rows\n",
    "\n",
    "WORLD_CITY_TABLE = build_city_table()\n",
    "\n",
    "# ================================================================\n",
    "# Background attributes (coarse) — optional\n",
    "# ================================================================\n",
    "COUNTRY_LANG_PALETTE = {\n",
    "    \"India\": [\"Hindi\",\"English\",\"Bengali\",\"Telugu\",\"Marathi\",\"Tamil\",\"Urdu\",\"Gujarati\",\"Kannada\",\"Malayalam\",\"Punjabi\"],\n",
    "    \"USA\": [\"English\",\"Spanish\"], \"UK\": [\"English\"], \"Canada\": [\"English\",\"French\"],\n",
    "    \"Mexico\": [\"Spanish\"], \"Brazil\": [\"Portuguese\"], \"France\": [\"French\"], \"Germany\": [\"German\"],\n",
    "    \"Spain\": [\"Spanish\",\"Catalan\"], \"Italy\": [\"Italian\"], \"Netherlands\": [\"Dutch\"], \"Sweden\": [\"Swedish\"],\n",
    "    \"Turkey\": [\"Turkish\"], \"UAE\": [\"Arabic\",\"English\"], \"Saudi Arabia\": [\"Arabic\"], \"Egypt\": [\"Arabic\"],\n",
    "    \"Nigeria\": [\"English\",\"Yoruba\",\"Hausa\",\"Igbo\"], \"Kenya\": [\"English\",\"Swahili\"],\n",
    "    \"South Africa\": [\"English\",\"Zulu\",\"Xhosa\",\"Afrikaans\"], \"Ethiopia\": [\"Amharic\",\"Oromo\",\"Tigrinya\"],\n",
    "    \"Bangladesh\": [\"Bengali\"], \"Pakistan\": [\"Urdu\",\"Punjabi\",\"Pashto\",\"Sindhi\"], \"Sri Lanka\": [\"Sinhala\",\"Tamil\"],\n",
    "    \"Nepal\": [\"Nepali\"], \"Japan\": [\"Japanese\"], \"South Korea\": [\"Korean\"], \"China\": [\"Mandarin\"],\n",
    "    \"Hong Kong\": [\"Cantonese\",\"English\"], \"Taiwan\": [\"Mandarin\"], \"Singapore\": [\"English\",\"Mandarin\",\"Malay\",\"Tamil\"],\n",
    "    \"Malaysia\": [\"Malay\",\"English\",\"Mandarin\",\"Tamil\"], \"Thailand\": [\"Thai\"], \"Indonesia\": [\"Indonesian\"],\n",
    "    \"Vietnam\": [\"Vietnamese\"], \"Philippines\": [\"Filipino\",\"English\"], \"Australia\": [\"English\"],\n",
    "    \"New Zealand\": [\"English\",\"Māori\"], \"Argentina\": [\"Spanish\"], \"Chile\": [\"Spanish\"], \"Peru\": [\"Spanish\"],\n",
    "    \"Colombia\": [\"Spanish\"], \"Uruguay\": [\"Spanish\"], \"Ecuador\": [\"Spanish\"],\n",
    "}\n",
    "\n",
    "COUNTRY_RELIGION_PALETTE = {\n",
    "    \"India\": [\"Hindu\",\"Muslim\",\"Christian\",\"Sikh\",\"Buddhist\",\"Jain\",\"Other\"],\n",
    "    \"USA\": [\"Christian\",\"Unaffiliated\",\"Jewish\",\"Muslim\",\"Hindu\",\"Buddhist\",\"Other\"],\n",
    "    \"UK\": [\"Christian\",\"Unaffiliated\",\"Muslim\",\"Hindu\",\"Sikh\",\"Jewish\",\"Buddhist\"],\n",
    "    \"Canada\": [\"Christian\",\"Unaffiliated\",\"Muslim\",\"Hindu\",\"Sikh\",\"Buddhist\",\"Jewish\"],\n",
    "    \"Mexico\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Brazil\": [\"Christian\",\"Spiritist\",\"Afro-Brazilian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"France\": [\"Unaffiliated\",\"Christian\",\"Muslim\",\"Jewish\",\"Buddhist\",\"Other\"],\n",
    "    \"Germany\": [\"Christian\",\"Unaffiliated\",\"Muslim\",\"Other\"], \"Spain\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"Italy\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Netherlands\": [\"Unaffiliated\",\"Christian\",\"Muslim\",\"Other\"],\n",
    "    \"Sweden\": [\"Unaffiliated\",\"Christian\",\"Other\"], \"Turkey\": [\"Muslim\",\"Other\"], \"UAE\": [\"Muslim\",\"Christian\",\"Hindu\",\"Buddhist\",\"Other\"],\n",
    "    \"Saudi Arabia\": [\"Muslim\",\"Other\"], \"Egypt\": [\"Muslim\",\"Christian\",\"Other\"],\n",
    "    \"Nigeria\": [\"Christian\",\"Muslim\",\"Traditional\",\"Other\"], \"Kenya\": [\"Christian\",\"Muslim\",\"Traditional\",\"Other\"],\n",
    "    \"South Africa\": [\"Christian\",\"Traditional\",\"Unaffiliated\",\"Other\"], \"Ethiopia\": [\"Christian\",\"Muslim\",\"Other\"],\n",
    "    \"Bangladesh\": [\"Muslim\",\"Hindu\",\"Other\"], \"Pakistan\": [\"Muslim\",\"Other\"], \"Sri Lanka\": [\"Buddhist\",\"Hindu\",\"Muslim\",\"Christian\"],\n",
    "    \"Nepal\": [\"Hindu\",\"Buddhist\",\"Other\"], \"Japan\": [\"Shinto\",\"Buddhist\",\"Other\"], \"South Korea\": [\"Unaffiliated\",\"Christian\",\"Buddhist\",\"Other\"],\n",
    "    \"China\": [\"Unaffiliated\",\"Folk/Traditional\",\"Buddhist\",\"Christian\",\"Other\"], \"Hong Kong\": [\"Buddhist\",\"Taoist\",\"Christian\",\"Other\"],\n",
    "    \"Taiwan\": [\"Folk/Traditional\",\"Buddhist\",\"Taoist\",\"Other\"], \"Singapore\": [\"Buddhist\",\"Taoist\",\"Muslim\",\"Christian\",\"Hindu\",\"Other\"],\n",
    "    \"Malaysia\": [\"Muslim\",\"Buddhist\",\"Christian\",\"Hindu\",\"Other\"], \"Thailand\": [\"Buddhist\",\"Other\"],\n",
    "    \"Indonesia\": [\"Muslim\",\"Christian\",\"Hindu\",\"Buddhist\",\"Other\"], \"Vietnam\": [\"Unaffiliated\",\"Buddhist\",\"Christian\",\"Other\"],\n",
    "    \"Philippines\": [\"Christian\",\"Muslim\",\"Other\"], \"Australia\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"New Zealand\": [\"Unaffiliated\",\"Christian\",\"Other\"], \"Argentina\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"Chile\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Peru\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"Colombia\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Uruguay\": [\"Unaffiliated\",\"Christian\",\"Other\"],\n",
    "    \"Ecuador\": [\"Christian\",\"Other\"],\n",
    "}\n",
    "\n",
    "# ================================================================\n",
    "# Ethnicity mapping (coarse)\n",
    "# ================================================================\n",
    "ETHNICITY_LABELS = [\n",
    "    \"South Asian\",\"East Asian\",\"Southeast Asian\",\"Middle Eastern/North African\",\n",
    "    \"Black/African\",\"White/European\",\"Latino/Hispanic\",\"Pacific Islander\",\"Mixed/Other\"\n",
    "]\n",
    "\n",
    "COUNTRY_TO_ETHNICITY = {\n",
    "    \"India\": \"South Asian\", \"Pakistan\": \"South Asian\", \"Bangladesh\": \"South Asian\",\n",
    "    \"Sri Lanka\": \"South Asian\", \"Nepal\": \"South Asian\",\n",
    "    \"Japan\": \"East Asian\", \"South Korea\": \"East Asian\", \"China\": \"East Asian\",\n",
    "    \"Taiwan\": \"East Asian\", \"Hong Kong\": \"East Asian\",\n",
    "    \"Singapore\": \"Southeast Asian\", \"Malaysia\": \"Southeast Asian\", \"Thailand\": \"Southeast Asian\",\n",
    "    \"Indonesia\": \"Southeast Asian\", \"Vietnam\": \"Southeast Asian\", \"Philippines\": \"Southeast Asian\",\n",
    "    \"UAE\": \"Middle Eastern/North African\", \"Saudi Arabia\": \"Middle Eastern/North African\",\n",
    "    \"Egypt\": \"Middle Eastern/North African\", \"Türkiye\": \"Middle Eastern/North African\", \"Morocco\": \"Middle Eastern/North African\",\n",
    "    \"Nigeria\": \"Black/African\", \"Kenya\": \"Black/African\", \"Ghana\": \"Black/African\",\n",
    "    \"South Africa\": \"Black/African\", \"Ethiopia\": \"Black/African\",\n",
    "    \"Brazil\": \"Latino/Hispanic\", \"Argentina\": \"Latino/Hispanic\", \"Chile\": \"Latino/Hispanic\",\n",
    "    \"Peru\": \"Latino/Hispanic\", \"Colombia\": \"Latino/Hispanic\", \"Uruguay\": \"Latino/Hispanic\",\n",
    "    \"USA\": \"White/European\", \"Canada\": \"White/European\", \"Mexico\": \"Latino/Hispanic\",\n",
    "    \"UK\": \"White/European\", \"France\": \"White/European\", \"Germany\": \"White/European\",\n",
    "    \"Spain\": \"White/European\", \"Italy\": \"White/European\", \"Netherlands\": \"White/European\",\n",
    "    \"Austria\": \"White/European\", \"Sweden\": \"White/European\",\n",
    "    \"Australia\": \"White/European\", \"New Zealand\": \"White/European\",\n",
    "}\n",
    "\n",
    "# ================================================================\n",
    "# Photo provider\n",
    "# ================================================================\n",
    "PHOTO_CATALOG = {\n",
    "    \"South Asian\": [],\n",
    "    \"East Asian\": [],\n",
    "    \"Southeast Asian\": [],\n",
    "    \"Middle Eastern/North African\": [],\n",
    "    \"Black/African\": [],\n",
    "    \"White/European\": [],\n",
    "    \"Latino/Hispanic\": [],\n",
    "    \"Pacific Islander\": [],\n",
    "    \"Mixed/Other\": [],\n",
    "}\n",
    "\n",
    "def randomuser_url(pid: str, gender: str) -> str:\n",
    "    idx = int(pid, 16) % 100\n",
    "    if gender == \"Woman\":\n",
    "        folder = \"women\"\n",
    "    elif gender == \"Man\":\n",
    "        folder = \"men\"\n",
    "    else:\n",
    "        folder = \"women\" if (idx % 2 == 0) else \"men\"\n",
    "    return f\"https://randomuser.me/api/portraits/{folder}/{idx}.jpg\"\n",
    "\n",
    "def photo_url_for(gender: str, ethnicity: str, pid: str) -> str:\n",
    "    pool = PHOTO_CATALOG.get(ethnicity, [])\n",
    "    if pool:\n",
    "        return pool[int(pid, 16) % len(pool)]\n",
    "    return randomuser_url(pid, gender)\n",
    "\n",
    "# ================================================================\n",
    "# Helpers\n",
    "# ================================================================\n",
    "def weighted_choice(items, weights):\n",
    "    return rng.choices(items, weights=weights, k=1)[0]\n",
    "\n",
    "def build_city_table(include_india=True, india_tier_bias=(0.5, 0.35, 0.15)):\n",
    "    rows = []\n",
    "    if include_india:\n",
    "        tiers = [\"Tier-1\", \"Tier-2\", \"Tier-3\"]\n",
    "        tier_w = dict(zip(tiers, india_tier_bias))\n",
    "        for tier in tiers:\n",
    "            for country, city, w in INDIA_TIERS[tier]:\n",
    "                rows.append((\"South Asia\", country, city, w * (1 + 9 * tier_w[tier])))\n",
    "    for region, cities in WORLD_REGIONS.items():\n",
    "        for country, city, w in cities:\n",
    "            rows.append((region, country, city, w))\n",
    "    return rows\n",
    "\n",
    "WORLD_CITY_TABLE = build_city_table()\n",
    "\n",
    "def sample_world_city():\n",
    "    weights = [w for (_, _, _, w) in WORLD_CITY_TABLE]\n",
    "    choices = [(r, ctry, cty) for (r, ctry, cty, _) in WORLD_CITY_TABLE]\n",
    "    return rng.choices(choices, weights=weights, k=1)[0]\n",
    "\n",
    "def sample_gender():\n",
    "    return rng.choices(GENDERS, weights=[0.47, 0.47, 0.06], k=1)[0]\n",
    "\n",
    "def sample_name(gender):\n",
    "    if gender == \"Woman\":\n",
    "        pool = FEMALE_FIRST + UNISEX_FIRST\n",
    "    elif gender == \"Man\":\n",
    "        pool = MALE_FIRST + UNISEX_FIRST\n",
    "    else:\n",
    "        pool = UNISEX_FIRST + FEMALE_FIRST[:10] + MALE_FIRST[:10]\n",
    "    return rng.choice(pool)\n",
    "\n",
    "def truncated_normal(mean, sd, lo, hi):\n",
    "    while True:\n",
    "        x = rng.gauss(mean, sd)\n",
    "        if lo <= x <= hi:\n",
    "            return int(round(x))\n",
    "\n",
    "def sample_age(region):\n",
    "    mean = 27\n",
    "    if region in {\"Europe\",\"North America\"}: mean = 29\n",
    "    if region in {\"South Asia\",\"South Asia (non-India)\",\"Africa\",\"Sub-Saharan Africa\"}: mean = 26\n",
    "    return truncated_normal(mean, 4.5, 21, 45)\n",
    "\n",
    "def sample_distance_km(region):\n",
    "    lam = 1 / 6.0\n",
    "    val = int(round(min(30, max(1, rng.expovariate(lam)))))\n",
    "    if region in {\"Europe\",\"North America\"} and rng.random() < 0.25:\n",
    "        val = min(30, val + rng.randint(2,5))\n",
    "    return val\n",
    "\n",
    "def pick_interest_cluster(age, region):\n",
    "    w = {\"Active\":1,\"Arts\":1,\"Geek\":1,\"Social\":1,\"Sports\":1}\n",
    "    if age <= 26: w[\"Geek\"] += 0.6; w[\"Social\"] += 0.4\n",
    "    if age >= 30: w[\"Arts\"] += 0.4; w[\"Active\"] += 0.2\n",
    "    if region in {\"Europe\",\"North America\"}: w[\"Arts\"] += 0.2\n",
    "    if region in {\"South Asia\",\"South Asia (non-India)\",\"East Asia\"}: w[\"Geek\"] += 0.3\n",
    "    keys = list(INTEREST_CLUSTERS.keys())\n",
    "    return rng.choices(keys, weights=[w[k] for k in keys], k=1)[0]\n",
    "\n",
    "def sample_interests(age, region):\n",
    "    k = rng.randint(3,6)\n",
    "    base = pick_interest_cluster(age, region)\n",
    "    alt = base if rng.random() < 0.6 else rng.choice(list(INTEREST_CLUSTERS.keys()))\n",
    "    pool = list(dict.fromkeys(INTEREST_CLUSTERS[base] + INTEREST_CLUSTERS[alt]))\n",
    "    if rng.random() < 0.35:\n",
    "        extras = [i for i in ALL_INTERESTS if i not in pool]\n",
    "        if extras:\n",
    "            pool += rng.sample(extras, k=min(3, len(extras)))\n",
    "    rng.shuffle(pool)\n",
    "    return pool[:k]\n",
    "\n",
    "def make_bio(name, age, city, interests):\n",
    "    lead = rng.choice([\n",
    "        \"Powered by coffee and chaotic good energy.\",\n",
    "        \"Part-time explorer, full-time snack enthusiast.\",\n",
    "        \"Weekends = long walks + long playlists.\",\n",
    "        \"Trying new things and new foods—recommendations welcome.\",\n",
    "        \"Recovering overthinker, thriving bruncher.\",\n",
    "        \"Swaps memes for restaurant tips.\",\n",
    "    ])\n",
    "    hook = rng.choice([\n",
    "        f\"Into {interests[0].lower()} and {interests[1].lower()}\",\n",
    "        f\"{interests[0]} > {interests[1]}? Discuss.\",\n",
    "        f\"If you like {interests[0].lower()}, we’ll get along.\",\n",
    "        f\"From {city}, chasing {interests[-1].lower()} vibes.\",\n",
    "        f\"{interests[0]}, {interests[1]}, and probably {interests[-1].lower()}\",\n",
    "    ])\n",
    "    closer = rng.choice([\n",
    "        \"Coffee then a walk?\",\n",
    "        \"Open to spontaneous day trips.\",\n",
    "        \"Here for good banter and better food.\",\n",
    "        \"Teach me your niche skill.\",\n",
    "        \"Playlist swaps encouraged.\",\n",
    "    ])\n",
    "    return f\"{lead} {hook}. {closer}\"\n",
    "\n",
    "def sample_languages(country, k_max=2):\n",
    "    pool = COUNTRY_LANG_PALETTE.get(country, [\"English\"])\n",
    "    k = 1 if len(pool) == 1 else rng.randint(1, min(k_max, len(pool)))\n",
    "    return rng.sample(pool, k=k)\n",
    "\n",
    "def sample_religion(country):\n",
    "    pool = COUNTRY_RELIGION_PALETTE.get(country, [\"Other\"])\n",
    "    return rng.choice(pool)\n",
    "\n",
    "def country_to_ethnicity(country):\n",
    "    return COUNTRY_TO_ETHNICITY.get(country, \"Mixed/Other\")\n",
    "\n",
    "# ================================================================\n",
    "# NEW: deterministic, seed-based IDs (stable across runs for same seed)\n",
    "# ================================================================\n",
    "def stable_profile_id(seed: int, i: int, name: str, city: str, gender: str) -> str:\n",
    "    basis = f\"{seed}::{i}::{name}::{city}::{gender}\"\n",
    "    return uuid.uuid5(uuid.NAMESPACE_URL, basis).hex[:8]\n",
    "\n",
    "# ================================================================\n",
    "# Main generator\n",
    "# ================================================================\n",
    "def make_world_profiles(n=N_PROFILES, seed=DEFAULT_SEED):\n",
    "    rng.seed(seed)\n",
    "    rows = []\n",
    "    for i in range(n):\n",
    "        region, country, city = sample_world_city()\n",
    "        gender = sample_gender()\n",
    "        name = sample_name(gender)\n",
    "        age = sample_age(region)\n",
    "        distance = sample_distance_km(region)\n",
    "        interests = sample_interests(age, region)\n",
    "        bio = make_bio(name, age, city, interests)\n",
    "        languages = sample_languages(country)\n",
    "        religion = sample_religion(country)\n",
    "        ethnicity = country_to_ethnicity(country)\n",
    "\n",
    "        pid = stable_profile_id(seed, i, name, city, gender)\n",
    "        photo_url = photo_url_for(gender, ethnicity, pid)\n",
    "\n",
    "        rows.append({\n",
    "            \"id\": pid,\n",
    "            \"name\": name,\n",
    "            \"age\": age,\n",
    "            \"gender\": gender,\n",
    "            \"region\": region,\n",
    "            \"country\": country,\n",
    "            \"city\": city,\n",
    "            \"distance_km\": distance,\n",
    "            \"ethnicity\": ethnicity,\n",
    "            \"languages\": languages,\n",
    "            \"religion\": religion,\n",
    "            \"interests\": interests,\n",
    "            \"about\": bio,\n",
    "            \"photo_url\": photo_url,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ================================================================\n",
    "# Optional: save with JSON-encoded list columns\n",
    "# ================================================================\n",
    "def save_profiles_csv(df: pd.DataFrame, path: str):\n",
    "    out = df.copy()\n",
    "    for col in [\"languages\", \"interests\"]:\n",
    "        if col in out.columns:\n",
    "            out[col] = out[col].apply(json.dumps, ensure_ascii=False)\n",
    "    out.to_csv(path, index=False)\n",
    "\n",
    "df = make_world_profiles(n=10000, seed=123)\n",
    "# save_profiles_csv(df, \"world_profiles.csv\")\n"
   ],
   "id": "a765f7408094de51",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-09T07:38:00.997651Z",
     "start_time": "2025-11-09T07:38:00.959211Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "profiles = pd.read_csv(\"./data/profiles.csv\")\n",
    "viewers = pd.read_csv(\"./data/viewers.csv\")\n",
    "interactions = pd.read_csv(\"./data/interactions.csv\", names=['datetime', 'viewer_id', 'viewer_name', 'profile_id','profile_name', 'status', 'score'])"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T10:59:40.347337Z",
     "start_time": "2025-11-15T10:59:31.451129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "profiles['text'] = profiles.drop(columns=['id']).astype(str).agg(\" - \".join, axis=1)\n",
    "embeddings = model.encode(profiles['text'], batch_size=128, convert_to_numpy=True, normalize_embeddings=True)\n",
    "profiles['embedding'] = list(embeddings)"
   ],
   "id": "1a4bb1e6fbda4787",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudhirsingh/PyCharmProjects/story/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sudhirsingh/PyCharmProjects/story/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'profiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msentence_transformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SentenceTransformer\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m SentenceTransformer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall-MiniLM-L6-v2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m profiles[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mprofiles\u001B[49m\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mstr\u001B[39m)\u001B[38;5;241m.\u001B[39magg(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m - \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      5\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode(profiles[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m], batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, convert_to_numpy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, normalize_embeddings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      6\u001B[0m profiles[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(embeddings)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'profiles' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:38:15.747608Z",
     "start_time": "2025-11-09T07:38:15.740488Z"
    }
   },
   "cell_type": "code",
   "source": "profiles[['id', 'embedding']]",
   "id": "6c99045b8530a792",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             id                                          embedding\n",
       "0      ssse1024  [-0.005661143, -0.0029685695, 0.0457694, -0.01...\n",
       "1      d8334dc0  [-0.002191868, -0.012887895, 0.05675405, 0.026...\n",
       "2      309e9139  [0.030787738, 0.043839186, 0.0544222, -0.01888...\n",
       "3      7899f9e2  [0.063246764, 0.0684222, 0.07976355, 0.0779395...\n",
       "4      fde9c9f3  [-0.05164085, 0.0015087755, 0.010844314, 0.065...\n",
       "...         ...                                                ...\n",
       "9996   c25d98dc  [-0.061014995, -0.011367507, 0.0038794263, 0.0...\n",
       "9997   1fab6d6a  [-0.03792872, -0.022427015, -0.032286942, 0.05...\n",
       "9998   c2ae6461  [-0.050376404, -0.040498063, 0.023308842, 0.01...\n",
       "9999   acaeab0e  [-0.0025407786, -0.049863584, -0.03467388, 0.0...\n",
       "10000  f8fe1303  [0.048929457, -0.049330596, 0.047011595, 0.036...\n",
       "\n",
       "[10001 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ssse1024</td>\n",
       "      <td>[-0.005661143, -0.0029685695, 0.0457694, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d8334dc0</td>\n",
       "      <td>[-0.002191868, -0.012887895, 0.05675405, 0.026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309e9139</td>\n",
       "      <td>[0.030787738, 0.043839186, 0.0544222, -0.01888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7899f9e2</td>\n",
       "      <td>[0.063246764, 0.0684222, 0.07976355, 0.0779395...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fde9c9f3</td>\n",
       "      <td>[-0.05164085, 0.0015087755, 0.010844314, 0.065...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>c25d98dc</td>\n",
       "      <td>[-0.061014995, -0.011367507, 0.0038794263, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1fab6d6a</td>\n",
       "      <td>[-0.03792872, -0.022427015, -0.032286942, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>c2ae6461</td>\n",
       "      <td>[-0.050376404, -0.040498063, 0.023308842, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>acaeab0e</td>\n",
       "      <td>[-0.0025407786, -0.049863584, -0.03467388, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>f8fe1303</td>\n",
       "      <td>[0.048929457, -0.049330596, 0.047011595, 0.036...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1b370786fb7f261f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:18:44.323196Z",
     "start_time": "2025-11-09T07:18:35.575615Z"
    }
   },
   "cell_type": "code",
   "source": "profiles[['id', 'embedding']].to_csv(\"./data/profile_embedding.csv\", index=False)",
   "id": "99fbe1181cb9ef8b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e5f7553afd858b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "62fead69282b290d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T07:23:51.531973Z",
     "start_time": "2025-11-19T07:23:51.262813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import random, uuid, json\n",
    "from datetime import datetime\n",
    "\n",
    "# ================================================================\n",
    "# Config: global RNG & sizes\n",
    "# ================================================================\n",
    "DEFAULT_SEED = 123\n",
    "N_PROFILES = 10_000\n",
    "rng = random.Random(DEFAULT_SEED)\n",
    "\n",
    "# ================================================================\n",
    "# Taxonomies\n",
    "# ================================================================\n",
    "GENDERS = [\"Woman\", \"Man\", \"Non-binary\"]\n",
    "\n",
    "INTEREST_CLUSTERS = {\n",
    "    \"Active\": [\"Hiking\", \"Running\", \"Yoga\", \"Dancing\", \"Photography\"],\n",
    "    \"Arts\": [\"Art\", \"Theatre\", \"Poetry\", \"Movies\", \"Music\"],\n",
    "    \"Geek\": [\"Tech\", \"Gaming\", \"Startups\", \"Board Games\"],\n",
    "    \"Social\": [\"Foodie\", \"Travel\", \"Standup Comedy\", \"Volunteering\"],\n",
    "    \"Sports\": [\"Cricket\", \"Football\", \"Basketball\"],\n",
    "}\n",
    "ALL_INTERESTS = sorted({i for v in INTEREST_CLUSTERS.values() for i in v})\n",
    "\n",
    "# Name pools (extend as you like)\n",
    "FEMALE_FIRST = [\n",
    "    \"Aditi\",\"Aarohi\",\"Anaya\",\"Diya\",\"Isha\",\"Myra\",\"Sara\",\"Siya\",\"Tara\",\"Zara\",\n",
    "    \"Neha\",\"Priya\",\"Naina\",\"Rhea\",\"Meera\",\"Anika\",\"Kavya\",\"Ritu\",\"Pooja\",\"Sana\",\n",
    "    \"Anna\",\"Maria\",\"Sofia\",\"Emma\",\"Olivia\",\"Mia\",\"Aisha\",\"Fatima\",\"Yuna\",\"Mei\",\n",
    "    \"Camila\",\"Valentina\",\"Amara\",\"Zainab\",\"Helena\",\"Elena\",\"Giulia\",\"Lina\",\"Aya\"\n",
    "]\n",
    "MALE_FIRST = [\n",
    "    \"Aarav\",\"Vivaan\",\"Aditya\",\"Vihaan\",\"Arjun\",\"Sai\",\"Krishna\",\"Ishaan\",\"Rohan\",\"Kabir\",\n",
    "    \"Raghav\",\"Aman\",\"Rajat\",\"Varun\",\"Anil\",\"Rahul\",\"Aakash\",\"Nikhil\",\"Sandeep\",\"Yash\",\n",
    "    \"Liam\",\"Noah\",\"Lucas\",\"Mateo\",\"Ethan\",\"Leo\",\"Hiro\",\"Daichi\",\"Minjun\",\"Jae\",\n",
    "    \"Luis\",\"Diego\",\"Andre\",\"Omar\",\"Youssef\",\"Ali\",\"Marco\",\"Jonas\",\"Felix\",\"Tariq\"\n",
    "]\n",
    "UNISEX_FIRST = [\"Sam\",\"Dev\",\"Shiv\",\"Arya\",\"Sasha\",\"Riyaan\",\"Jai\",\"Ray\",\"Kiran\",\"Alex\",\"Charlie\",\"Noor\",\"Ariel\",\"Jordan\",\"Kai\"]\n",
    "\n",
    "# ================================================================\n",
    "# Geography: India tiers + global regions\n",
    "# Weights are rough, population-leaning proxies (tune freely)\n",
    "# ================================================================\n",
    "INDIA_TIERS = {\n",
    "    \"Tier-1\": [\n",
    "        (\"India\", \"Mumbai\", 10),\n",
    "        (\"India\", \"Delhi\", 10),\n",
    "        (\"India\", \"Bengaluru\", 9),\n",
    "        (\"India\", \"Hyderabad\", 8),\n",
    "        (\"India\", \"Chennai\", 7),\n",
    "        (\"India\", \"Kolkata\", 7),\n",
    "        (\"India\", \"Pune\", 6),\n",
    "        (\"India\", \"Ahmedabad\", 5),\n",
    "    ],\n",
    "    \"Tier-2\": [\n",
    "        (\"India\", \"Jaipur\", 4), (\"India\", \"Surat\", 4), (\"India\", \"Lucknow\", 4),\n",
    "        (\"India\", \"Kanpur\", 3), (\"India\", \"Nagpur\", 3), (\"India\", \"Indore\", 3),\n",
    "        (\"India\", \"Bhopal\", 3), (\"India\", \"Chandigarh\", 2), (\"India\", \"Kochi\", 2),\n",
    "        (\"India\", \"Coimbatore\", 2),\n",
    "    ],\n",
    "    \"Tier-3\": [\n",
    "        (\"India\", \"Patna\", 2), (\"India\", \"Guwahati\", 2), (\"India\", \"Visakhapatnam\", 2),\n",
    "        (\"India\", \"Vijayawada\", 2), (\"India\", \"Bhubaneswar\", 2), (\"India\", \"Thiruvananthapuram\", 2),\n",
    "        (\"India\", \"Vadodara\", 2), (\"India\", \"Nashik\", 2), (\"India\", \"Ludhiana\", 2), (\"India\", \"Rajkot\", 2),\n",
    "    ],\n",
    "}\n",
    "\n",
    "WORLD_REGIONS = {\n",
    "    \"South Asia (non-India)\": [\n",
    "        (\"Bangladesh\", \"Dhaka\", 8), (\"Bangladesh\", \"Chittagong\", 3),\n",
    "        (\"Pakistan\", \"Karachi\", 9), (\"Pakistan\", \"Lahore\", 6), (\"Pakistan\", \"Islamabad\", 2),\n",
    "        (\"Sri Lanka\", \"Colombo\", 2), (\"Nepal\", \"Kathmandu\", 2),\n",
    "    ],\n",
    "    \"East Asia\": [\n",
    "        (\"Japan\", \"Tokyo\", 10), (\"Japan\", \"Osaka\", 4),\n",
    "        (\"South Korea\", \"Seoul\", 8), (\"South Korea\", \"Busan\", 3),\n",
    "        (\"China\", \"Shanghai\", 10), (\"China\", \"Beijing\", 9), (\"China\", \"Shenzhen\", 7), (\"China\", \"Guangzhou\", 7),\n",
    "        (\"Taiwan\", \"Taipei\", 4), (\"Hong Kong\", \"Hong Kong\", 5),\n",
    "    ],\n",
    "    \"Southeast Asia\": [\n",
    "        (\"Singapore\", \"Singapore\", 6),\n",
    "        (\"Malaysia\", \"Kuala Lumpur\", 4),\n",
    "        (\"Thailand\", \"Bangkok\", 7),\n",
    "        (\"Indonesia\", \"Jakarta\", 9), (\"Vietnam\", \"Ho Chi Minh City\", 6), (\"Vietnam\", \"Hanoi\", 5),\n",
    "        (\"Philippines\", \"Manila\", 8),\n",
    "    ],\n",
    "    \"North America\": [\n",
    "        (\"USA\", \"New York\", 9), (\"USA\", \"Los Angeles\", 8), (\"USA\", \"Chicago\", 6),\n",
    "        (\"USA\", \"San Francisco\", 5), (\"USA\", \"Houston\", 5), (\"USA\", \"Miami\", 5),\n",
    "        (\"Canada\", \"Toronto\", 6), (\"Canada\", \"Vancouver\", 4), (\"Canada\", \"Montreal\", 4),\n",
    "        (\"Mexico\", \"Mexico City\", 9), (\"Mexico\", \"Guadalajara\", 4),\n",
    "    ],\n",
    "    \"Europe\": [\n",
    "        (\"UK\", \"London\", 9), (\"France\", \"Paris\", 8), (\"Germany\", \"Berlin\", 6),\n",
    "        (\"Spain\", \"Madrid\", 5), (\"Spain\", \"Barcelona\", 5),\n",
    "        (\"Italy\", \"Rome\", 5), (\"Italy\", \"Milan\", 4),\n",
    "        (\"Netherlands\", \"Amsterdam\", 4), (\"Austria\", \"Vienna\", 4), (\"Sweden\", \"Stockholm\", 3),\n",
    "    ],\n",
    "    \"MENA\": [\n",
    "        (\"UAE\", \"Dubai\", 7), (\"UAE\", \"Abu Dhabi\", 4),\n",
    "        (\"Saudi Arabia\", \"Riyadh\", 6), (\"Saudi Arabia\", \"Jeddah\", 5),\n",
    "        (\"Egypt\", \"Cairo\", 8), (\"Egypt\", \"Alexandria\", 4),\n",
    "        (\"Türkiye\", \"Istanbul\", 8), (\"Morocco\", \"Casablanca\", 4),\n",
    "    ],\n",
    "    \"Sub-Saharan Africa\": [\n",
    "        (\"Nigeria\", \"Lagos\", 9), (\"Nigeria\", \"Abuja\", 4),\n",
    "        (\"Kenya\", \"Nairobi\", 6), (\"Kenya\", \"Mombasa\", 3),\n",
    "        (\"Ghana\", \"Accra\", 4), (\"Ghana\", \"Kumasi\", 3),\n",
    "        (\"South Africa\", \"Johannesburg\", 5), (\"South Africa\", \"Cape Town\", 5), (\"South Africa\", \"Durban\", 3),\n",
    "        (\"Ethiopia\", \"Addis Ababa\", 5),\n",
    "    ],\n",
    "    \"Latin America\": [\n",
    "        (\"Brazil\", \"São Paulo\", 10), (\"Brazil\", \"Rio de Janeiro\", 7),\n",
    "        (\"Argentina\", \"Buenos Aires\", 8), (\"Chile\", \"Santiago\", 6),\n",
    "        (\"Peru\", \"Lima\", 7), (\"Colombia\", \"Bogotá\", 7), (\"Colombia\", \"Medellín\", 4),\n",
    "        (\"Ecuador\", \"Quito\", 3), (\"Uruguay\", \"Montevideo\", 3),\n",
    "    ],\n",
    "    \"Oceania\": [\n",
    "        (\"Australia\", \"Sydney\", 6), (\"Australia\", \"Melbourne\", 6),\n",
    "        (\"Australia\", \"Brisbane\", 3), (\"Australia\", \"Perth\", 3),\n",
    "        (\"New Zealand\", \"Auckland\", 3), (\"New Zealand\", \"Wellington\", 2),\n",
    "    ],\n",
    "}\n",
    "\n",
    "def build_city_table(include_india=True, india_tier_bias=(0.5, 0.35, 0.15)):\n",
    "    rows = []\n",
    "    if include_india:\n",
    "        tiers = [\"Tier-1\", \"Tier-2\", \"Tier-3\"]\n",
    "        tier_w = dict(zip(tiers, india_tier_bias))\n",
    "        for tier in tiers:\n",
    "            for country, city, w in INDIA_TIERS[tier]:\n",
    "                rows.append((\"South Asia\", country, city, w * (1 + 9 * tier_w[tier])))\n",
    "    for region, cities in WORLD_REGIONS.items():\n",
    "        for country, city, w in cities:\n",
    "            rows.append((region, country, city, w))\n",
    "    return rows\n",
    "\n",
    "WORLD_CITY_TABLE = build_city_table()\n",
    "\n",
    "# ================================================================\n",
    "# Background attributes (coarse) — optional\n",
    "# ================================================================\n",
    "COUNTRY_LANG_PALETTE = {\n",
    "    \"India\": [\"Hindi\",\"English\",\"Bengali\",\"Telugu\",\"Marathi\",\"Tamil\",\"Urdu\",\"Gujarati\",\"Kannada\",\"Malayalam\",\"Punjabi\"],\n",
    "    \"USA\": [\"English\",\"Spanish\"], \"UK\": [\"English\"], \"Canada\": [\"English\",\"French\"],\n",
    "    \"Mexico\": [\"Spanish\"], \"Brazil\": [\"Portuguese\"], \"France\": [\"French\"], \"Germany\": [\"German\"],\n",
    "    \"Spain\": [\"Spanish\",\"Catalan\"], \"Italy\": [\"Italian\"], \"Netherlands\": [\"Dutch\"], \"Sweden\": [\"Swedish\"],\n",
    "    \"Turkey\": [\"Turkish\"], \"UAE\": [\"Arabic\",\"English\"], \"Saudi Arabia\": [\"Arabic\"], \"Egypt\": [\"Arabic\"],\n",
    "    \"Nigeria\": [\"English\",\"Yoruba\",\"Hausa\",\"Igbo\"], \"Kenya\": [\"English\",\"Swahili\"],\n",
    "    \"South Africa\": [\"English\",\"Zulu\",\"Xhosa\",\"Afrikaans\"], \"Ethiopia\": [\"Amharic\",\"Oromo\",\"Tigrinya\"],\n",
    "    \"Bangladesh\": [\"Bengali\"], \"Pakistan\": [\"Urdu\",\"Punjabi\",\"Pashto\",\"Sindhi\"], \"Sri Lanka\": [\"Sinhala\",\"Tamil\"],\n",
    "    \"Nepal\": [\"Nepali\"], \"Japan\": [\"Japanese\"], \"South Korea\": [\"Korean\"], \"China\": [\"Mandarin\"],\n",
    "    \"Hong Kong\": [\"Cantonese\",\"English\"], \"Taiwan\": [\"Mandarin\"], \"Singapore\": [\"English\",\"Mandarin\",\"Malay\",\"Tamil\"],\n",
    "    \"Malaysia\": [\"Malay\",\"English\",\"Mandarin\",\"Tamil\"], \"Thailand\": [\"Thai\"], \"Indonesia\": [\"Indonesian\"],\n",
    "    \"Vietnam\": [\"Vietnamese\"], \"Philippines\": [\"Filipino\",\"English\"], \"Australia\": [\"English\"],\n",
    "    \"New Zealand\": [\"English\",\"Māori\"], \"Argentina\": [\"Spanish\"], \"Chile\": [\"Spanish\"], \"Peru\": [\"Spanish\"],\n",
    "    \"Colombia\": [\"Spanish\"], \"Uruguay\": [\"Spanish\"], \"Ecuador\": [\"Spanish\"],\n",
    "}\n",
    "\n",
    "COUNTRY_RELIGION_PALETTE = {\n",
    "    \"India\": [\"Hindu\",\"Muslim\",\"Christian\",\"Sikh\",\"Buddhist\",\"Jain\",\"Other\"],\n",
    "    \"USA\": [\"Christian\",\"Unaffiliated\",\"Jewish\",\"Muslim\",\"Hindu\",\"Buddhist\",\"Other\"],\n",
    "    \"UK\": [\"Christian\",\"Unaffiliated\",\"Muslim\",\"Hindu\",\"Sikh\",\"Jewish\",\"Buddhist\"],\n",
    "    \"Canada\": [\"Christian\",\"Unaffiliated\",\"Muslim\",\"Hindu\",\"Sikh\",\"Buddhist\",\"Jewish\"],\n",
    "    \"Mexico\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Brazil\": [\"Christian\",\"Spiritist\",\"Afro-Brazilian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"France\": [\"Unaffiliated\",\"Christian\",\"Muslim\",\"Jewish\",\"Buddhist\",\"Other\"],\n",
    "    \"Germany\": [\"Christian\",\"Unaffiliated\",\"Muslim\",\"Other\"], \"Spain\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"Italy\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Netherlands\": [\"Unaffiliated\",\"Christian\",\"Muslim\",\"Other\"],\n",
    "    \"Sweden\": [\"Unaffiliated\",\"Christian\",\"Other\"], \"Turkey\": [\"Muslim\",\"Other\"], \"UAE\": [\"Muslim\",\"Christian\",\"Hindu\",\"Buddhist\",\"Other\"],\n",
    "    \"Saudi Arabia\": [\"Muslim\",\"Other\"], \"Egypt\": [\"Muslim\",\"Christian\",\"Other\"],\n",
    "    \"Nigeria\": [\"Christian\",\"Muslim\",\"Traditional\",\"Other\"], \"Kenya\": [\"Christian\",\"Muslim\",\"Traditional\",\"Other\"],\n",
    "    \"South Africa\": [\"Christian\",\"Traditional\",\"Unaffiliated\",\"Other\"], \"Ethiopia\": [\"Christian\",\"Muslim\",\"Other\"],\n",
    "    \"Bangladesh\": [\"Muslim\",\"Hindu\",\"Other\"], \"Pakistan\": [\"Muslim\",\"Other\"], \"Sri Lanka\": [\"Buddhist\",\"Hindu\",\"Muslim\",\"Christian\"],\n",
    "    \"Nepal\": [\"Hindu\",\"Buddhist\",\"Other\"], \"Japan\": [\"Shinto\",\"Buddhist\",\"Other\"], \"South Korea\": [\"Unaffiliated\",\"Christian\",\"Buddhist\",\"Other\"],\n",
    "    \"China\": [\"Unaffiliated\",\"Folk/Traditional\",\"Buddhist\",\"Christian\",\"Other\"], \"Hong Kong\": [\"Buddhist\",\"Taoist\",\"Christian\",\"Other\"],\n",
    "    \"Taiwan\": [\"Folk/Traditional\",\"Buddhist\",\"Taoist\",\"Other\"], \"Singapore\": [\"Buddhist\",\"Taoist\",\"Muslim\",\"Christian\",\"Hindu\",\"Other\"],\n",
    "    \"Malaysia\": [\"Muslim\",\"Buddhist\",\"Christian\",\"Hindu\",\"Other\"], \"Thailand\": [\"Buddhist\",\"Other\"],\n",
    "    \"Indonesia\": [\"Muslim\",\"Christian\",\"Hindu\",\"Buddhist\",\"Other\"], \"Vietnam\": [\"Unaffiliated\",\"Buddhist\",\"Christian\",\"Other\"],\n",
    "    \"Philippines\": [\"Christian\",\"Muslim\",\"Other\"], \"Australia\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"New Zealand\": [\"Unaffiliated\",\"Christian\",\"Other\"], \"Argentina\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"Chile\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Peru\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "    \"Colombia\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Uruguay\": [\"Unaffiliated\",\"Christian\",\"Other\"],\n",
    "    \"Ecuador\": [\"Christian\",\"Other\"],\n",
    "}\n",
    "\n",
    "# ================================================================\n",
    "# Ethnicity mapping (coarse)\n",
    "# ================================================================\n",
    "ETHNICITY_LABELS = [\n",
    "    \"South Asian\",\"East Asian\",\"Southeast Asian\",\"Middle Eastern/North African\",\n",
    "    \"Black/African\",\"White/European\",\"Latino/Hispanic\",\"Pacific Islander\",\"Mixed/Other\"\n",
    "]\n",
    "\n",
    "COUNTRY_TO_ETHNICITY = {\n",
    "    \"India\": \"South Asian\", \"Pakistan\": \"South Asian\", \"Bangladesh\": \"South Asian\",\n",
    "    \"Sri Lanka\": \"South Asian\", \"Nepal\": \"South Asian\",\n",
    "    \"Japan\": \"East Asian\", \"South Korea\": \"East Asian\", \"China\": \"East Asian\",\n",
    "    \"Taiwan\": \"East Asian\", \"Hong Kong\": \"East Asian\",\n",
    "    \"Singapore\": \"Southeast Asian\", \"Malaysia\": \"Southeast Asian\", \"Thailand\": \"Southeast Asian\",\n",
    "    \"Indonesia\": \"Southeast Asian\", \"Vietnam\": \"Southeast Asian\", \"Philippines\": \"Southeast Asian\",\n",
    "    \"UAE\": \"Middle Eastern/North African\", \"Saudi Arabia\": \"Middle Eastern/North African\",\n",
    "    \"Egypt\": \"Middle Eastern/North African\", \"Türkiye\": \"Middle Eastern/North African\", \"Morocco\": \"Middle Eastern/North African\",\n",
    "    \"Nigeria\": \"Black/African\", \"Kenya\": \"Black/African\", \"Ghana\": \"Black/African\",\n",
    "    \"South Africa\": \"Black/African\", \"Ethiopia\": \"Black/African\",\n",
    "    \"Brazil\": \"Latino/Hispanic\", \"Argentina\": \"Latino/Hispanic\", \"Chile\": \"Latino/Hispanic\",\n",
    "    \"Peru\": \"Latino/Hispanic\", \"Colombia\": \"Latino/Hispanic\", \"Uruguay\": \"Latino/Hispanic\",\n",
    "    \"USA\": \"White/European\", \"Canada\": \"White/European\", \"Mexico\": \"Latino/Hispanic\",\n",
    "    \"UK\": \"White/European\", \"France\": \"White/European\", \"Germany\": \"White/European\",\n",
    "    \"Spain\": \"White/European\", \"Italy\": \"White/European\", \"Netherlands\": \"White/European\",\n",
    "    \"Austria\": \"White/European\", \"Sweden\": \"White/European\",\n",
    "    \"Australia\": \"White/European\", \"New Zealand\": \"White/European\",\n",
    "}\n",
    "\n",
    "# ================================================================\n",
    "# Photo provider\n",
    "# ================================================================\n",
    "PHOTO_CATALOG = {\n",
    "    \"South Asian\": [],\n",
    "    \"East Asian\": [],\n",
    "    \"Southeast Asian\": [],\n",
    "    \"Middle Eastern/North African\": [],\n",
    "    \"Black/African\": [],\n",
    "    \"White/European\": [],\n",
    "    \"Latino/Hispanic\": [],\n",
    "    \"Pacific Islander\": [],\n",
    "    \"Mixed/Other\": [],\n",
    "}\n",
    "\n",
    "def randomuser_url(pid: str, gender: str) -> str:\n",
    "    idx = int(pid, 16) % 100\n",
    "    if gender == \"Woman\":\n",
    "        folder = \"women\"\n",
    "    elif gender == \"Man\":\n",
    "        folder = \"men\"\n",
    "    else:\n",
    "        folder = \"women\" if (idx % 2 == 0) else \"men\"\n",
    "    return f\"https://randomuser.me/api/portraits/{folder}/{idx}.jpg\"\n",
    "\n",
    "def photo_url_for(gender: str, ethnicity: str, pid: str) -> str:\n",
    "    pool = PHOTO_CATALOG.get(ethnicity, [])\n",
    "    if pool:\n",
    "        return pool[int(pid, 16) % len(pool)]\n",
    "    return randomuser_url(pid, gender)\n",
    "\n",
    "# ================================================================\n",
    "# Helpers\n",
    "# ================================================================\n",
    "def weighted_choice(items, weights):\n",
    "    return rng.choices(items, weights=weights, k=1)[0]\n",
    "\n",
    "def build_city_table(include_india=True, india_tier_bias=(0.5, 0.35, 0.15)):\n",
    "    rows = []\n",
    "    if include_india:\n",
    "        tiers = [\"Tier-1\", \"Tier-2\", \"Tier-3\"]\n",
    "        tier_w = dict(zip(tiers, india_tier_bias))\n",
    "        for tier in tiers:\n",
    "            for country, city, w in INDIA_TIERS[tier]:\n",
    "                rows.append((\"South Asia\", country, city, w * (1 + 9 * tier_w[tier])))\n",
    "    for region, cities in WORLD_REGIONS.items():\n",
    "        for country, city, w in cities:\n",
    "            rows.append((region, country, city, w))\n",
    "    return rows\n",
    "\n",
    "WORLD_CITY_TABLE = build_city_table()\n",
    "\n",
    "def sample_world_city():\n",
    "    weights = [w for (_, _, _, w) in WORLD_CITY_TABLE]\n",
    "    choices = [(r, ctry, cty) for (r, ctry, cty, _) in WORLD_CITY_TABLE]\n",
    "    return rng.choices(choices, weights=weights, k=1)[0]\n",
    "\n",
    "def sample_gender():\n",
    "    return rng.choices(GENDERS, weights=[0.47, 0.47, 0.06], k=1)[0]\n",
    "\n",
    "def sample_name(gender):\n",
    "    if gender == \"Woman\":\n",
    "        pool = FEMALE_FIRST + UNISEX_FIRST\n",
    "    elif gender == \"Man\":\n",
    "        pool = MALE_FIRST + UNISEX_FIRST\n",
    "    else:\n",
    "        pool = UNISEX_FIRST + FEMALE_FIRST[:10] + MALE_FIRST[:10]\n",
    "    return rng.choice(pool)\n",
    "\n",
    "def truncated_normal(mean, sd, lo, hi):\n",
    "    while True:\n",
    "        x = rng.gauss(mean, sd)\n",
    "        if lo <= x <= hi:\n",
    "            return int(round(x))\n",
    "\n",
    "def sample_age(region):\n",
    "    mean = 27\n",
    "    if region in {\"Europe\",\"North America\"}: mean = 29\n",
    "    if region in {\"South Asia\",\"South Asia (non-India)\",\"Africa\",\"Sub-Saharan Africa\"}: mean = 26\n",
    "    return truncated_normal(mean, 4.5, 21, 45)\n",
    "\n",
    "def sample_distance_km(region):\n",
    "    lam = 1 / 6.0\n",
    "    val = int(round(min(30, max(1, rng.expovariate(lam)))))\n",
    "    if region in {\"Europe\",\"North America\"} and rng.random() < 0.25:\n",
    "        val = min(30, val + rng.randint(2,5))\n",
    "    return val\n",
    "\n",
    "def pick_interest_cluster(age, region):\n",
    "    w = {\"Active\":1,\"Arts\":1,\"Geek\":1,\"Social\":1,\"Sports\":1}\n",
    "    if age <= 26: w[\"Geek\"] += 0.6; w[\"Social\"] += 0.4\n",
    "    if age >= 30: w[\"Arts\"] += 0.4; w[\"Active\"] += 0.2\n",
    "    if region in {\"Europe\",\"North America\"}: w[\"Arts\"] += 0.2\n",
    "    if region in {\"South Asia\",\"South Asia (non-India)\",\"East Asia\"}: w[\"Geek\"] += 0.3\n",
    "    keys = list(INTEREST_CLUSTERS.keys())\n",
    "    return rng.choices(keys, weights=[w[k] for k in keys], k=1)[0]\n",
    "\n",
    "def sample_interests(age, region):\n",
    "    k = rng.randint(3,6)\n",
    "    base = pick_interest_cluster(age, region)\n",
    "    alt = base if rng.random() < 0.6 else rng.choice(list(INTEREST_CLUSTERS.keys()))\n",
    "    pool = list(dict.fromkeys(INTEREST_CLUSTERS[base] + INTEREST_CLUSTERS[alt]))\n",
    "    if rng.random() < 0.35:\n",
    "        extras = [i for i in ALL_INTERESTS if i not in pool]\n",
    "        if extras:\n",
    "            pool += rng.sample(extras, k=min(3, len(extras)))\n",
    "    rng.shuffle(pool)\n",
    "    return pool[:k]\n",
    "\n",
    "def make_bio(name, age, city, interests):\n",
    "    lead = rng.choice([\n",
    "        \"Powered by coffee and chaotic good energy.\",\n",
    "        \"Part-time explorer, full-time snack enthusiast.\",\n",
    "        \"Weekends = long walks + long playlists.\",\n",
    "        \"Trying new things and new foods—recommendations welcome.\",\n",
    "        \"Recovering overthinker, thriving bruncher.\",\n",
    "        \"Swaps memes for restaurant tips.\",\n",
    "    ])\n",
    "    hook = rng.choice([\n",
    "        f\"Into {interests[0].lower()} and {interests[1].lower()}\",\n",
    "        f\"{interests[0]} > {interests[1]}? Discuss.\",\n",
    "        f\"If you like {interests[0].lower()}, we’ll get along.\",\n",
    "        f\"From {city}, chasing {interests[-1].lower()} vibes.\",\n",
    "        f\"{interests[0]}, {interests[1]}, and probably {interests[-1].lower()}\",\n",
    "    ])\n",
    "    closer = rng.choice([\n",
    "        \"Coffee then a walk?\",\n",
    "        \"Open to spontaneous day trips.\",\n",
    "        \"Here for good banter and better food.\",\n",
    "        \"Teach me your niche skill.\",\n",
    "        \"Playlist swaps encouraged.\",\n",
    "    ])\n",
    "    return f\"{lead} {hook}. {closer}\"\n",
    "\n",
    "def sample_languages(country, k_max=2):\n",
    "    pool = COUNTRY_LANG_PALETTE.get(country, [\"English\"])\n",
    "    k = 1 if len(pool) == 1 else rng.randint(1, min(k_max, len(pool)))\n",
    "    return rng.sample(pool, k=k)\n",
    "\n",
    "def sample_religion(country):\n",
    "    pool = COUNTRY_RELIGION_PALETTE.get(country, [\"Other\"])\n",
    "    return rng.choice(pool)\n",
    "\n",
    "def country_to_ethnicity(country):\n",
    "    return COUNTRY_TO_ETHNICITY.get(country, \"Mixed/Other\")\n",
    "\n",
    "# ================================================================\n",
    "# NEW: deterministic, seed-based IDs (stable across runs for same seed)\n",
    "# ================================================================\n",
    "def stable_profile_id(seed: int, i: int, name: str, city: str, gender: str) -> str:\n",
    "    basis = f\"{seed}::{i}::{name}::{city}::{gender}\"\n",
    "    return uuid.uuid5(uuid.NAMESPACE_URL, basis).hex[:8]\n",
    "\n",
    "# ================================================================\n",
    "# Main generator\n",
    "# ================================================================\n",
    "def make_world_profiles(n=N_PROFILES, seed=DEFAULT_SEED):\n",
    "    rng.seed(seed)\n",
    "    rows = []\n",
    "    for i in range(n):\n",
    "        region, country, city = sample_world_city()\n",
    "        gender = sample_gender()\n",
    "        name = sample_name(gender)\n",
    "        age = sample_age(region)\n",
    "        distance = sample_distance_km(region)\n",
    "        interests = sample_interests(age, region)\n",
    "        bio = make_bio(name, age, city, interests)\n",
    "        languages = sample_languages(country)\n",
    "        religion = sample_religion(country)\n",
    "        ethnicity = country_to_ethnicity(country)\n",
    "\n",
    "        pid = stable_profile_id(seed, i, name, city, gender)\n",
    "        photo_url = photo_url_for(gender, ethnicity, pid)\n",
    "\n",
    "        rows.append({\n",
    "            \"id\": pid,\n",
    "            \"name\": name,\n",
    "            \"age\": age,\n",
    "            \"gender\": gender,\n",
    "            \"region\": region,\n",
    "            \"country\": country,\n",
    "            \"city\": city,\n",
    "            \"distance_km\": distance,\n",
    "            \"ethnicity\": ethnicity,\n",
    "            \"languages\": languages,\n",
    "            \"religion\": religion,\n",
    "            \"interests\": interests,\n",
    "            \"about\": bio,\n",
    "            \"photo_url\": photo_url,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ================================================================\n",
    "# Optional: save with JSON-encoded list columns\n",
    "# ================================================================\n",
    "def save_profiles_csv(df: pd.DataFrame, path: str):\n",
    "    out = df.copy()\n",
    "    for col in [\"languages\", \"interests\"]:\n",
    "        if col in out.columns:\n",
    "            out[col] = out[col].apply(json.dumps, ensure_ascii=False)\n",
    "    out.to_csv(path, index=False)\n",
    "\n",
    "\n",
    "# save_profiles_csv(df, \"world_profiles.csv\")\n",
    "\n",
    "\n"
   ],
   "id": "b7fc4d0ddb3a333a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T07:19:03.489676Z",
     "start_time": "2025-11-19T07:19:03.299406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from supabase import create_client, Client\n",
    "\n",
    "url: str = \"https://tpquhacpoxoschgsarie.supabase.co\"\n",
    "key: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRwcXVoYWNwb3hvc2NoZ3NhcmllIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjMyMTk3NjksImV4cCI6MjA3ODc5NTc2OX0.T06IB1qnCr8eL1BCvuSypVkS7Cgeu5wdnE8QrSWmb-w\"\n",
    "\n",
    "if not url or not key:\n",
    "    print(\"Please set SUPABASE_URL and SUPABASE_KEY environment variables.\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "supabase: Client = create_client(url, key)\n",
    "\n"
   ],
   "id": "1a057dcef6bcb06b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T07:51:16.266188Z",
     "start_time": "2025-11-19T07:51:15.776036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "from supabase import create_client\n",
    "from postgrest import APIError  # may raise; keep for clarity but we catch generic Exception too\n",
    "\n",
    "\n",
    "def normalize_profile(p):\n",
    "    # minimal normalizer from earlier\n",
    "    if 'distance_km' in p:\n",
    "        try:\n",
    "            fv = float(p['distance_km'])\n",
    "            p['distance_km'] = int(fv) if fv.is_integer() else fv\n",
    "        except Exception:\n",
    "            p.pop('distance_km', None)\n",
    "    if 'languages' in p and not isinstance(p['languages'], list):\n",
    "        p['languages'] = [p['languages']]\n",
    "    if 'interests' in p and not isinstance(p['interests'], list):\n",
    "        p['interests'] = [p['interests']]\n",
    "    if 'age' in p:\n",
    "        try:\n",
    "            p['age'] = int(p['age'])\n",
    "        except Exception:\n",
    "            p['age'] = None\n",
    "    return p\n",
    "\n",
    "def safe_response_to_dict(resp):\n",
    "    \"\"\"\n",
    "    Convert the API response to a plain dict in a way that works for\n",
    "    multiple client versions (pydantic v1 .dict(), v2 .model_dump()).\n",
    "    If neither exists, fall back to str(resp).\n",
    "    \"\"\"\n",
    "    if resp is None:\n",
    "        return {\"raw\": None}\n",
    "    # try common attributes first\n",
    "    for attr in (\"data\", \"error\", \"status_code\", \"status\"):\n",
    "        if hasattr(resp, attr):\n",
    "            # We won't return early; we'll build a dict below.\n",
    "            pass\n",
    "    # try pydantic model_dump (v2)\n",
    "    try:\n",
    "        return resp.model_dump()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # try pydantic .dict() (v1)\n",
    "    try:\n",
    "        return resp.dict()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # try to turn into map-like via .__dict__\n",
    "    try:\n",
    "        return dict(resp.__dict__)\n",
    "    except Exception:\n",
    "        return {\"raw\": str(resp)}\n",
    "\n",
    "def insert_profiles(rows, upsert=False):\n",
    "    \"\"\"\n",
    "    Insert or upsert rows and return a plain dict with keys like:\n",
    "      { \"data\": ..., \"error\": ..., \"status_code\": ... }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        table = supabase.table('people')\n",
    "        if upsert:\n",
    "            resp = table.upsert(rows).execute()\n",
    "        else:\n",
    "            resp = table.insert(rows).execute()\n",
    "    except Exception as e:\n",
    "        # This catches APIError, HTTP errors, connection issues, etc.\n",
    "        return {\"data\": None, \"error\": {\"message\": str(e), \"type\": type(e).__name__}}\n",
    "\n",
    "    resp_dict = safe_response_to_dict(resp)\n",
    "\n",
    "    # Standardize common shapes: some clients return {\"data\":..., \"error\":...}\n",
    "    # Others wrap in top-level keys. Try to detect.\n",
    "    if \"error\" not in resp_dict and \"data\" not in resp_dict:\n",
    "        # maybe the dict has top-level keys like 'body' or similar; just return for inspection\n",
    "        # but try to detect nested pattern\n",
    "        for k in (\"body\", \"result\", \"response\"):\n",
    "            if k in resp_dict and isinstance(resp_dict[k], dict):\n",
    "                nested = resp_dict[k]\n",
    "                if \"error\" in nested or \"data\" in nested:\n",
    "                    return nested\n",
    "        # fallback\n",
    "        return resp_dict\n",
    "\n",
    "    return resp_dict\n",
    "\n",
    "\n",
    "# Example chunked loader using the robust function:\n",
    "def full_load(profiles, chunk_size=200, upsert=True):\n",
    "\n",
    "    import sys\n",
    "    from supabase import create_client, Client\n",
    "\n",
    "    url: str = \"https://tpquhacpoxoschgsarie.supabase.co\"\n",
    "    key: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRwcXVoYWNwb3hvc2NoZ3NhcmllIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjMyMTk3NjksImV4cCI6MjA3ODc5NTc2OX0.T06IB1qnCr8eL1BCvuSypVkS7Cgeu5wdnE8QrSWmb-w\"\n",
    "\n",
    "    if not url or not key:\n",
    "        print(\"Please set SUPABASE_URL and SUPABASE_KEY environment variables.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    supabase: Client = create_client(url, key)\n",
    "    # normalize in-place (or copy if you prefer)\n",
    "\n",
    "    import pandas as pd\n",
    "    import random, uuid, json\n",
    "    from datetime import datetime\n",
    "\n",
    "    # ================================================================\n",
    "    # Config: global RNG & sizes\n",
    "    # ================================================================\n",
    "    DEFAULT_SEED = 123\n",
    "    N_PROFILES = 10_000\n",
    "    rng = random.Random(DEFAULT_SEED)\n",
    "\n",
    "    # ================================================================\n",
    "    # Taxonomies\n",
    "    # ================================================================\n",
    "    GENDERS = [\"Woman\", \"Man\", \"Non-binary\"]\n",
    "\n",
    "    INTEREST_CLUSTERS = {\n",
    "        \"Active\": [\"Hiking\", \"Running\", \"Yoga\", \"Dancing\", \"Photography\"],\n",
    "        \"Arts\": [\"Art\", \"Theatre\", \"Poetry\", \"Movies\", \"Music\"],\n",
    "        \"Geek\": [\"Tech\", \"Gaming\", \"Startups\", \"Board Games\"],\n",
    "        \"Social\": [\"Foodie\", \"Travel\", \"Standup Comedy\", \"Volunteering\"],\n",
    "        \"Sports\": [\"Cricket\", \"Football\", \"Basketball\"],\n",
    "    }\n",
    "    ALL_INTERESTS = sorted({i for v in INTEREST_CLUSTERS.values() for i in v})\n",
    "\n",
    "    # Name pools (extend as you like)\n",
    "    FEMALE_FIRST = [\n",
    "        \"Aditi\",\"Aarohi\",\"Anaya\",\"Diya\",\"Isha\",\"Myra\",\"Sara\",\"Siya\",\"Tara\",\"Zara\",\n",
    "        \"Neha\",\"Priya\",\"Naina\",\"Rhea\",\"Meera\",\"Anika\",\"Kavya\",\"Ritu\",\"Pooja\",\"Sana\",\n",
    "        \"Anna\",\"Maria\",\"Sofia\",\"Emma\",\"Olivia\",\"Mia\",\"Aisha\",\"Fatima\",\"Yuna\",\"Mei\",\n",
    "        \"Camila\",\"Valentina\",\"Amara\",\"Zainab\",\"Helena\",\"Elena\",\"Giulia\",\"Lina\",\"Aya\"\n",
    "    ]\n",
    "    MALE_FIRST = [\n",
    "        \"Aarav\",\"Vivaan\",\"Aditya\",\"Vihaan\",\"Arjun\",\"Sai\",\"Krishna\",\"Ishaan\",\"Rohan\",\"Kabir\",\n",
    "        \"Raghav\",\"Aman\",\"Rajat\",\"Varun\",\"Anil\",\"Rahul\",\"Aakash\",\"Nikhil\",\"Sandeep\",\"Yash\",\n",
    "        \"Liam\",\"Noah\",\"Lucas\",\"Mateo\",\"Ethan\",\"Leo\",\"Hiro\",\"Daichi\",\"Minjun\",\"Jae\",\n",
    "        \"Luis\",\"Diego\",\"Andre\",\"Omar\",\"Youssef\",\"Ali\",\"Marco\",\"Jonas\",\"Felix\",\"Tariq\"\n",
    "    ]\n",
    "    UNISEX_FIRST = [\"Sam\",\"Dev\",\"Shiv\",\"Arya\",\"Sasha\",\"Riyaan\",\"Jai\",\"Ray\",\"Kiran\",\"Alex\",\"Charlie\",\"Noor\",\"Ariel\",\"Jordan\",\"Kai\"]\n",
    "\n",
    "    # ================================================================\n",
    "    # Geography: India tiers + global regions\n",
    "    # Weights are rough, population-leaning proxies (tune freely)\n",
    "    # ================================================================\n",
    "    INDIA_TIERS = {\n",
    "        \"Tier-1\": [\n",
    "            (\"India\", \"Mumbai\", 10),\n",
    "            (\"India\", \"Delhi\", 10),\n",
    "            (\"India\", \"Bengaluru\", 9),\n",
    "            (\"India\", \"Hyderabad\", 8),\n",
    "            (\"India\", \"Chennai\", 7),\n",
    "            (\"India\", \"Kolkata\", 7),\n",
    "            (\"India\", \"Pune\", 6),\n",
    "            (\"India\", \"Ahmedabad\", 5),\n",
    "        ],\n",
    "        \"Tier-2\": [\n",
    "            (\"India\", \"Jaipur\", 4), (\"India\", \"Surat\", 4), (\"India\", \"Lucknow\", 4),\n",
    "            (\"India\", \"Kanpur\", 3), (\"India\", \"Nagpur\", 3), (\"India\", \"Indore\", 3),\n",
    "            (\"India\", \"Bhopal\", 3), (\"India\", \"Chandigarh\", 2), (\"India\", \"Kochi\", 2),\n",
    "            (\"India\", \"Coimbatore\", 2),\n",
    "        ],\n",
    "        \"Tier-3\": [\n",
    "            (\"India\", \"Patna\", 2), (\"India\", \"Guwahati\", 2), (\"India\", \"Visakhapatnam\", 2),\n",
    "            (\"India\", \"Vijayawada\", 2), (\"India\", \"Bhubaneswar\", 2), (\"India\", \"Thiruvananthapuram\", 2),\n",
    "            (\"India\", \"Vadodara\", 2), (\"India\", \"Nashik\", 2), (\"India\", \"Ludhiana\", 2), (\"India\", \"Rajkot\", 2),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    WORLD_REGIONS = {\n",
    "        \"South Asia (non-India)\": [\n",
    "            (\"Bangladesh\", \"Dhaka\", 8), (\"Bangladesh\", \"Chittagong\", 3),\n",
    "            (\"Pakistan\", \"Karachi\", 9), (\"Pakistan\", \"Lahore\", 6), (\"Pakistan\", \"Islamabad\", 2),\n",
    "            (\"Sri Lanka\", \"Colombo\", 2), (\"Nepal\", \"Kathmandu\", 2),\n",
    "        ],\n",
    "        \"East Asia\": [\n",
    "            (\"Japan\", \"Tokyo\", 10), (\"Japan\", \"Osaka\", 4),\n",
    "            (\"South Korea\", \"Seoul\", 8), (\"South Korea\", \"Busan\", 3),\n",
    "            (\"China\", \"Shanghai\", 10), (\"China\", \"Beijing\", 9), (\"China\", \"Shenzhen\", 7), (\"China\", \"Guangzhou\", 7),\n",
    "            (\"Taiwan\", \"Taipei\", 4), (\"Hong Kong\", \"Hong Kong\", 5),\n",
    "        ],\n",
    "        \"Southeast Asia\": [\n",
    "            (\"Singapore\", \"Singapore\", 6),\n",
    "            (\"Malaysia\", \"Kuala Lumpur\", 4),\n",
    "            (\"Thailand\", \"Bangkok\", 7),\n",
    "            (\"Indonesia\", \"Jakarta\", 9), (\"Vietnam\", \"Ho Chi Minh City\", 6), (\"Vietnam\", \"Hanoi\", 5),\n",
    "            (\"Philippines\", \"Manila\", 8),\n",
    "        ],\n",
    "        \"North America\": [\n",
    "            (\"USA\", \"New York\", 9), (\"USA\", \"Los Angeles\", 8), (\"USA\", \"Chicago\", 6),\n",
    "            (\"USA\", \"San Francisco\", 5), (\"USA\", \"Houston\", 5), (\"USA\", \"Miami\", 5),\n",
    "            (\"Canada\", \"Toronto\", 6), (\"Canada\", \"Vancouver\", 4), (\"Canada\", \"Montreal\", 4),\n",
    "            (\"Mexico\", \"Mexico City\", 9), (\"Mexico\", \"Guadalajara\", 4),\n",
    "        ],\n",
    "        \"Europe\": [\n",
    "            (\"UK\", \"London\", 9), (\"France\", \"Paris\", 8), (\"Germany\", \"Berlin\", 6),\n",
    "            (\"Spain\", \"Madrid\", 5), (\"Spain\", \"Barcelona\", 5),\n",
    "            (\"Italy\", \"Rome\", 5), (\"Italy\", \"Milan\", 4),\n",
    "            (\"Netherlands\", \"Amsterdam\", 4), (\"Austria\", \"Vienna\", 4), (\"Sweden\", \"Stockholm\", 3),\n",
    "        ],\n",
    "        \"MENA\": [\n",
    "            (\"UAE\", \"Dubai\", 7), (\"UAE\", \"Abu Dhabi\", 4),\n",
    "            (\"Saudi Arabia\", \"Riyadh\", 6), (\"Saudi Arabia\", \"Jeddah\", 5),\n",
    "            (\"Egypt\", \"Cairo\", 8), (\"Egypt\", \"Alexandria\", 4),\n",
    "            (\"Türkiye\", \"Istanbul\", 8), (\"Morocco\", \"Casablanca\", 4),\n",
    "        ],\n",
    "        \"Sub-Saharan Africa\": [\n",
    "            (\"Nigeria\", \"Lagos\", 9), (\"Nigeria\", \"Abuja\", 4),\n",
    "            (\"Kenya\", \"Nairobi\", 6), (\"Kenya\", \"Mombasa\", 3),\n",
    "            (\"Ghana\", \"Accra\", 4), (\"Ghana\", \"Kumasi\", 3),\n",
    "            (\"South Africa\", \"Johannesburg\", 5), (\"South Africa\", \"Cape Town\", 5), (\"South Africa\", \"Durban\", 3),\n",
    "            (\"Ethiopia\", \"Addis Ababa\", 5),\n",
    "        ],\n",
    "        \"Latin America\": [\n",
    "            (\"Brazil\", \"São Paulo\", 10), (\"Brazil\", \"Rio de Janeiro\", 7),\n",
    "            (\"Argentina\", \"Buenos Aires\", 8), (\"Chile\", \"Santiago\", 6),\n",
    "            (\"Peru\", \"Lima\", 7), (\"Colombia\", \"Bogotá\", 7), (\"Colombia\", \"Medellín\", 4),\n",
    "            (\"Ecuador\", \"Quito\", 3), (\"Uruguay\", \"Montevideo\", 3),\n",
    "        ],\n",
    "        \"Oceania\": [\n",
    "            (\"Australia\", \"Sydney\", 6), (\"Australia\", \"Melbourne\", 6),\n",
    "            (\"Australia\", \"Brisbane\", 3), (\"Australia\", \"Perth\", 3),\n",
    "            (\"New Zealand\", \"Auckland\", 3), (\"New Zealand\", \"Wellington\", 2),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def build_city_table(include_india=True, india_tier_bias=(0.5, 0.35, 0.15)):\n",
    "        rows = []\n",
    "        if include_india:\n",
    "            tiers = [\"Tier-1\", \"Tier-2\", \"Tier-3\"]\n",
    "            tier_w = dict(zip(tiers, india_tier_bias))\n",
    "            for tier in tiers:\n",
    "                for country, city, w in INDIA_TIERS[tier]:\n",
    "                    rows.append((\"South Asia\", country, city, w * (1 + 9 * tier_w[tier])))\n",
    "        for region, cities in WORLD_REGIONS.items():\n",
    "            for country, city, w in cities:\n",
    "                rows.append((region, country, city, w))\n",
    "        return rows\n",
    "\n",
    "    WORLD_CITY_TABLE = build_city_table()\n",
    "\n",
    "    # ================================================================\n",
    "    # Background attributes (coarse) — optional\n",
    "    # ================================================================\n",
    "    COUNTRY_LANG_PALETTE = {\n",
    "        \"India\": [\"Hindi\",\"English\",\"Bengali\",\"Telugu\",\"Marathi\",\"Tamil\",\"Urdu\",\"Gujarati\",\"Kannada\",\"Malayalam\",\"Punjabi\"],\n",
    "        \"USA\": [\"English\",\"Spanish\"], \"UK\": [\"English\"], \"Canada\": [\"English\",\"French\"],\n",
    "        \"Mexico\": [\"Spanish\"], \"Brazil\": [\"Portuguese\"], \"France\": [\"French\"], \"Germany\": [\"German\"],\n",
    "        \"Spain\": [\"Spanish\",\"Catalan\"], \"Italy\": [\"Italian\"], \"Netherlands\": [\"Dutch\"], \"Sweden\": [\"Swedish\"],\n",
    "        \"Turkey\": [\"Turkish\"], \"UAE\": [\"Arabic\",\"English\"], \"Saudi Arabia\": [\"Arabic\"], \"Egypt\": [\"Arabic\"],\n",
    "        \"Nigeria\": [\"English\",\"Yoruba\",\"Hausa\",\"Igbo\"], \"Kenya\": [\"English\",\"Swahili\"],\n",
    "        \"South Africa\": [\"English\",\"Zulu\",\"Xhosa\",\"Afrikaans\"], \"Ethiopia\": [\"Amharic\",\"Oromo\",\"Tigrinya\"],\n",
    "        \"Bangladesh\": [\"Bengali\"], \"Pakistan\": [\"Urdu\",\"Punjabi\",\"Pashto\",\"Sindhi\"], \"Sri Lanka\": [\"Sinhala\",\"Tamil\"],\n",
    "        \"Nepal\": [\"Nepali\"], \"Japan\": [\"Japanese\"], \"South Korea\": [\"Korean\"], \"China\": [\"Mandarin\"],\n",
    "        \"Hong Kong\": [\"Cantonese\",\"English\"], \"Taiwan\": [\"Mandarin\"], \"Singapore\": [\"English\",\"Mandarin\",\"Malay\",\"Tamil\"],\n",
    "        \"Malaysia\": [\"Malay\",\"English\",\"Mandarin\",\"Tamil\"], \"Thailand\": [\"Thai\"], \"Indonesia\": [\"Indonesian\"],\n",
    "        \"Vietnam\": [\"Vietnamese\"], \"Philippines\": [\"Filipino\",\"English\"], \"Australia\": [\"English\"],\n",
    "        \"New Zealand\": [\"English\",\"Māori\"], \"Argentina\": [\"Spanish\"], \"Chile\": [\"Spanish\"], \"Peru\": [\"Spanish\"],\n",
    "        \"Colombia\": [\"Spanish\"], \"Uruguay\": [\"Spanish\"], \"Ecuador\": [\"Spanish\"],\n",
    "    }\n",
    "\n",
    "    COUNTRY_RELIGION_PALETTE = {\n",
    "        \"India\": [\"Hindu\",\"Muslim\",\"Christian\",\"Sikh\",\"Buddhist\",\"Jain\",\"Other\"],\n",
    "        \"USA\": [\"Christian\",\"Unaffiliated\",\"Jewish\",\"Muslim\",\"Hindu\",\"Buddhist\",\"Other\"],\n",
    "        \"UK\": [\"Christian\",\"Unaffiliated\",\"Muslim\",\"Hindu\",\"Sikh\",\"Jewish\",\"Buddhist\"],\n",
    "        \"Canada\": [\"Christian\",\"Unaffiliated\",\"Muslim\",\"Hindu\",\"Sikh\",\"Buddhist\",\"Jewish\"],\n",
    "        \"Mexico\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Brazil\": [\"Christian\",\"Spiritist\",\"Afro-Brazilian\",\"Unaffiliated\",\"Other\"],\n",
    "        \"France\": [\"Unaffiliated\",\"Christian\",\"Muslim\",\"Jewish\",\"Buddhist\",\"Other\"],\n",
    "        \"Germany\": [\"Christian\",\"Unaffiliated\",\"Muslim\",\"Other\"], \"Spain\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "        \"Italy\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Netherlands\": [\"Unaffiliated\",\"Christian\",\"Muslim\",\"Other\"],\n",
    "        \"Sweden\": [\"Unaffiliated\",\"Christian\",\"Other\"], \"Turkey\": [\"Muslim\",\"Other\"], \"UAE\": [\"Muslim\",\"Christian\",\"Hindu\",\"Buddhist\",\"Other\"],\n",
    "        \"Saudi Arabia\": [\"Muslim\",\"Other\"], \"Egypt\": [\"Muslim\",\"Christian\",\"Other\"],\n",
    "        \"Nigeria\": [\"Christian\",\"Muslim\",\"Traditional\",\"Other\"], \"Kenya\": [\"Christian\",\"Muslim\",\"Traditional\",\"Other\"],\n",
    "        \"South Africa\": [\"Christian\",\"Traditional\",\"Unaffiliated\",\"Other\"], \"Ethiopia\": [\"Christian\",\"Muslim\",\"Other\"],\n",
    "        \"Bangladesh\": [\"Muslim\",\"Hindu\",\"Other\"], \"Pakistan\": [\"Muslim\",\"Other\"], \"Sri Lanka\": [\"Buddhist\",\"Hindu\",\"Muslim\",\"Christian\"],\n",
    "        \"Nepal\": [\"Hindu\",\"Buddhist\",\"Other\"], \"Japan\": [\"Shinto\",\"Buddhist\",\"Other\"], \"South Korea\": [\"Unaffiliated\",\"Christian\",\"Buddhist\",\"Other\"],\n",
    "        \"China\": [\"Unaffiliated\",\"Folk/Traditional\",\"Buddhist\",\"Christian\",\"Other\"], \"Hong Kong\": [\"Buddhist\",\"Taoist\",\"Christian\",\"Other\"],\n",
    "        \"Taiwan\": [\"Folk/Traditional\",\"Buddhist\",\"Taoist\",\"Other\"], \"Singapore\": [\"Buddhist\",\"Taoist\",\"Muslim\",\"Christian\",\"Hindu\",\"Other\"],\n",
    "        \"Malaysia\": [\"Muslim\",\"Buddhist\",\"Christian\",\"Hindu\",\"Other\"], \"Thailand\": [\"Buddhist\",\"Other\"],\n",
    "        \"Indonesia\": [\"Muslim\",\"Christian\",\"Hindu\",\"Buddhist\",\"Other\"], \"Vietnam\": [\"Unaffiliated\",\"Buddhist\",\"Christian\",\"Other\"],\n",
    "        \"Philippines\": [\"Christian\",\"Muslim\",\"Other\"], \"Australia\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "        \"New Zealand\": [\"Unaffiliated\",\"Christian\",\"Other\"], \"Argentina\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "        \"Chile\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Peru\": [\"Christian\",\"Unaffiliated\",\"Other\"],\n",
    "        \"Colombia\": [\"Christian\",\"Unaffiliated\",\"Other\"], \"Uruguay\": [\"Unaffiliated\",\"Christian\",\"Other\"],\n",
    "        \"Ecuador\": [\"Christian\",\"Other\"],\n",
    "    }\n",
    "\n",
    "    # ================================================================\n",
    "    # Ethnicity mapping (coarse)\n",
    "    # ================================================================\n",
    "    ETHNICITY_LABELS = [\n",
    "        \"South Asian\",\"East Asian\",\"Southeast Asian\",\"Middle Eastern/North African\",\n",
    "        \"Black/African\",\"White/European\",\"Latino/Hispanic\",\"Pacific Islander\",\"Mixed/Other\"\n",
    "    ]\n",
    "\n",
    "    COUNTRY_TO_ETHNICITY = {\n",
    "        \"India\": \"South Asian\", \"Pakistan\": \"South Asian\", \"Bangladesh\": \"South Asian\",\n",
    "        \"Sri Lanka\": \"South Asian\", \"Nepal\": \"South Asian\",\n",
    "        \"Japan\": \"East Asian\", \"South Korea\": \"East Asian\", \"China\": \"East Asian\",\n",
    "        \"Taiwan\": \"East Asian\", \"Hong Kong\": \"East Asian\",\n",
    "        \"Singapore\": \"Southeast Asian\", \"Malaysia\": \"Southeast Asian\", \"Thailand\": \"Southeast Asian\",\n",
    "        \"Indonesia\": \"Southeast Asian\", \"Vietnam\": \"Southeast Asian\", \"Philippines\": \"Southeast Asian\",\n",
    "        \"UAE\": \"Middle Eastern/North African\", \"Saudi Arabia\": \"Middle Eastern/North African\",\n",
    "        \"Egypt\": \"Middle Eastern/North African\", \"Türkiye\": \"Middle Eastern/North African\", \"Morocco\": \"Middle Eastern/North African\",\n",
    "        \"Nigeria\": \"Black/African\", \"Kenya\": \"Black/African\", \"Ghana\": \"Black/African\",\n",
    "        \"South Africa\": \"Black/African\", \"Ethiopia\": \"Black/African\",\n",
    "        \"Brazil\": \"Latino/Hispanic\", \"Argentina\": \"Latino/Hispanic\", \"Chile\": \"Latino/Hispanic\",\n",
    "        \"Peru\": \"Latino/Hispanic\", \"Colombia\": \"Latino/Hispanic\", \"Uruguay\": \"Latino/Hispanic\",\n",
    "        \"USA\": \"White/European\", \"Canada\": \"White/European\", \"Mexico\": \"Latino/Hispanic\",\n",
    "        \"UK\": \"White/European\", \"France\": \"White/European\", \"Germany\": \"White/European\",\n",
    "        \"Spain\": \"White/European\", \"Italy\": \"White/European\", \"Netherlands\": \"White/European\",\n",
    "        \"Austria\": \"White/European\", \"Sweden\": \"White/European\",\n",
    "        \"Australia\": \"White/European\", \"New Zealand\": \"White/European\",\n",
    "    }\n",
    "\n",
    "    # ================================================================\n",
    "    # Photo provider\n",
    "    # ================================================================\n",
    "    PHOTO_CATALOG = {\n",
    "        \"South Asian\": [],\n",
    "        \"East Asian\": [],\n",
    "        \"Southeast Asian\": [],\n",
    "        \"Middle Eastern/North African\": [],\n",
    "        \"Black/African\": [],\n",
    "        \"White/European\": [],\n",
    "        \"Latino/Hispanic\": [],\n",
    "        \"Pacific Islander\": [],\n",
    "        \"Mixed/Other\": [],\n",
    "    }\n",
    "\n",
    "    def randomuser_url(pid: str, gender: str) -> str:\n",
    "        idx = int(pid, 16) % 100\n",
    "        if gender == \"Woman\":\n",
    "            folder = \"women\"\n",
    "        elif gender == \"Man\":\n",
    "            folder = \"men\"\n",
    "        else:\n",
    "            folder = \"women\" if (idx % 2 == 0) else \"men\"\n",
    "        return f\"https://randomuser.me/api/portraits/{folder}/{idx}.jpg\"\n",
    "\n",
    "    def photo_url_for(gender: str, ethnicity: str, pid: str) -> str:\n",
    "        pool = PHOTO_CATALOG.get(ethnicity, [])\n",
    "        if pool:\n",
    "            return pool[int(pid, 16) % len(pool)]\n",
    "        return randomuser_url(pid, gender)\n",
    "\n",
    "    # ================================================================\n",
    "    # Helpers\n",
    "    # ================================================================\n",
    "    def weighted_choice(items, weights):\n",
    "        return rng.choices(items, weights=weights, k=1)[0]\n",
    "\n",
    "    def build_city_table(include_india=True, india_tier_bias=(0.5, 0.35, 0.15)):\n",
    "        rows = []\n",
    "        if include_india:\n",
    "            tiers = [\"Tier-1\", \"Tier-2\", \"Tier-3\"]\n",
    "            tier_w = dict(zip(tiers, india_tier_bias))\n",
    "            for tier in tiers:\n",
    "                for country, city, w in INDIA_TIERS[tier]:\n",
    "                    rows.append((\"South Asia\", country, city, w * (1 + 9 * tier_w[tier])))\n",
    "        for region, cities in WORLD_REGIONS.items():\n",
    "            for country, city, w in cities:\n",
    "                rows.append((region, country, city, w))\n",
    "        return rows\n",
    "\n",
    "    WORLD_CITY_TABLE = build_city_table()\n",
    "\n",
    "    def sample_world_city():\n",
    "        weights = [w for (_, _, _, w) in WORLD_CITY_TABLE]\n",
    "        choices = [(r, ctry, cty) for (r, ctry, cty, _) in WORLD_CITY_TABLE]\n",
    "        return rng.choices(choices, weights=weights, k=1)[0]\n",
    "\n",
    "    def sample_gender():\n",
    "        return rng.choices(GENDERS, weights=[0.47, 0.47, 0.06], k=1)[0]\n",
    "\n",
    "    def sample_name(gender):\n",
    "        if gender == \"Woman\":\n",
    "            pool = FEMALE_FIRST + UNISEX_FIRST\n",
    "        elif gender == \"Man\":\n",
    "            pool = MALE_FIRST + UNISEX_FIRST\n",
    "        else:\n",
    "            pool = UNISEX_FIRST + FEMALE_FIRST[:10] + MALE_FIRST[:10]\n",
    "        return rng.choice(pool)\n",
    "\n",
    "    def truncated_normal(mean, sd, lo, hi):\n",
    "        while True:\n",
    "            x = rng.gauss(mean, sd)\n",
    "            if lo <= x <= hi:\n",
    "                return int(round(x))\n",
    "\n",
    "    def sample_age(region):\n",
    "        mean = 27\n",
    "        if region in {\"Europe\",\"North America\"}: mean = 29\n",
    "        if region in {\"South Asia\",\"South Asia (non-India)\",\"Africa\",\"Sub-Saharan Africa\"}: mean = 26\n",
    "        return truncated_normal(mean, 4.5, 21, 45)\n",
    "\n",
    "    def sample_distance_km(region):\n",
    "        lam = 1 / 6.0\n",
    "        val = int(round(min(30, max(1, rng.expovariate(lam)))))\n",
    "        if region in {\"Europe\",\"North America\"} and rng.random() < 0.25:\n",
    "            val = min(30, val + rng.randint(2,5))\n",
    "        return val\n",
    "\n",
    "    def pick_interest_cluster(age, region):\n",
    "        w = {\"Active\":1,\"Arts\":1,\"Geek\":1,\"Social\":1,\"Sports\":1}\n",
    "        if age <= 26: w[\"Geek\"] += 0.6; w[\"Social\"] += 0.4\n",
    "        if age >= 30: w[\"Arts\"] += 0.4; w[\"Active\"] += 0.2\n",
    "        if region in {\"Europe\",\"North America\"}: w[\"Arts\"] += 0.2\n",
    "        if region in {\"South Asia\",\"South Asia (non-India)\",\"East Asia\"}: w[\"Geek\"] += 0.3\n",
    "        keys = list(INTEREST_CLUSTERS.keys())\n",
    "        return rng.choices(keys, weights=[w[k] for k in keys], k=1)[0]\n",
    "\n",
    "    def sample_interests(age, region):\n",
    "        k = rng.randint(3,6)\n",
    "        base = pick_interest_cluster(age, region)\n",
    "        alt = base if rng.random() < 0.6 else rng.choice(list(INTEREST_CLUSTERS.keys()))\n",
    "        pool = list(dict.fromkeys(INTEREST_CLUSTERS[base] + INTEREST_CLUSTERS[alt]))\n",
    "        if rng.random() < 0.35:\n",
    "            extras = [i for i in ALL_INTERESTS if i not in pool]\n",
    "            if extras:\n",
    "                pool += rng.sample(extras, k=min(3, len(extras)))\n",
    "        rng.shuffle(pool)\n",
    "        return pool[:k]\n",
    "\n",
    "    def make_bio(name, age, city, interests):\n",
    "        lead = rng.choice([\n",
    "            \"Powered by coffee and chaotic good energy.\",\n",
    "            \"Part-time explorer, full-time snack enthusiast.\",\n",
    "            \"Weekends = long walks + long playlists.\",\n",
    "            \"Trying new things and new foods—recommendations welcome.\",\n",
    "            \"Recovering overthinker, thriving bruncher.\",\n",
    "            \"Swaps memes for restaurant tips.\",\n",
    "        ])\n",
    "        hook = rng.choice([\n",
    "            f\"Into {interests[0].lower()} and {interests[1].lower()}\",\n",
    "            f\"{interests[0]} > {interests[1]}? Discuss.\",\n",
    "            f\"If you like {interests[0].lower()}, we’ll get along.\",\n",
    "            f\"From {city}, chasing {interests[-1].lower()} vibes.\",\n",
    "            f\"{interests[0]}, {interests[1]}, and probably {interests[-1].lower()}\",\n",
    "        ])\n",
    "        closer = rng.choice([\n",
    "            \"Coffee then a walk?\",\n",
    "            \"Open to spontaneous day trips.\",\n",
    "            \"Here for good banter and better food.\",\n",
    "            \"Teach me your niche skill.\",\n",
    "            \"Playlist swaps encouraged.\",\n",
    "        ])\n",
    "        return f\"{lead} {hook}. {closer}\"\n",
    "\n",
    "    def sample_languages(country, k_max=2):\n",
    "        pool = COUNTRY_LANG_PALETTE.get(country, [\"English\"])\n",
    "        k = 1 if len(pool) == 1 else rng.randint(1, min(k_max, len(pool)))\n",
    "        return rng.sample(pool, k=k)\n",
    "\n",
    "    def sample_religion(country):\n",
    "        pool = COUNTRY_RELIGION_PALETTE.get(country, [\"Other\"])\n",
    "        return rng.choice(pool)\n",
    "\n",
    "    def country_to_ethnicity(country):\n",
    "        return COUNTRY_TO_ETHNICITY.get(country, \"Mixed/Other\")\n",
    "\n",
    "    # ================================================================\n",
    "    # NEW: deterministic, seed-based IDs (stable across runs for same seed)\n",
    "    # ================================================================\n",
    "    def stable_profile_id(seed: int, i: int, name: str, city: str, gender: str) -> str:\n",
    "        basis = f\"{seed}::{i}::{name}::{city}::{gender}\"\n",
    "        return uuid.uuid5(uuid.NAMESPACE_URL, basis).hex[:8]\n",
    "\n",
    "    # ================================================================\n",
    "    # Main generator\n",
    "    # ================================================================\n",
    "    def make_world_profiles(n=N_PROFILES, seed=DEFAULT_SEED):\n",
    "        rng.seed(seed)\n",
    "        rows = []\n",
    "        for i in range(n):\n",
    "            region, country, city = sample_world_city()\n",
    "            gender = sample_gender()\n",
    "            name = sample_name(gender)\n",
    "            age = sample_age(region)\n",
    "            distance = sample_distance_km(region)\n",
    "            interests = sample_interests(age, region)\n",
    "            bio = make_bio(name, age, city, interests)\n",
    "            languages = sample_languages(country)\n",
    "            religion = sample_religion(country)\n",
    "            ethnicity = country_to_ethnicity(country)\n",
    "\n",
    "            pid = stable_profile_id(seed, i, name, city, gender)\n",
    "            photo_url = photo_url_for(gender, ethnicity, pid)\n",
    "\n",
    "            rows.append({\n",
    "                \"id\": pid,\n",
    "                \"name\": name,\n",
    "                \"age\": age,\n",
    "                \"gender\": gender,\n",
    "                \"region\": region,\n",
    "                \"country\": country,\n",
    "                \"city\": city,\n",
    "                \"distance_km\": distance,\n",
    "                \"ethnicity\": ethnicity,\n",
    "                \"languages\": languages,\n",
    "                \"religion\": religion,\n",
    "                \"interests\": interests,\n",
    "                \"about\": bio,\n",
    "                \"photo_url\": photo_url,\n",
    "            })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # ================================================================\n",
    "    # Optional: save with JSON-encoded list columns\n",
    "    # ================================================================\n",
    "    def save_profiles_csv(df: pd.DataFrame, path: str):\n",
    "        out = df.copy()\n",
    "        for col in [\"languages\", \"interests\"]:\n",
    "            if col in out.columns:\n",
    "                out[col] = out[col].apply(json.dumps, ensure_ascii=False)\n",
    "        out.to_csv(path, index=False)\n",
    "\n",
    "    profiles = make_world_profiles(n=10000)\n",
    "\n",
    "    # save_profiles_csv(df, \"world_profiles.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    profiles = [normalize_profile(dict(p)) for p in profiles]\n",
    "\n",
    "    def chunk_list(lst, n):\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i:i+n]\n",
    "\n",
    "    for idx, chunk in enumerate(chunk_list(profiles, chunk_size), start=1):\n",
    "        resp = insert_profiles(chunk, upsert=upsert)\n",
    "        # Print a concise but informative status\n",
    "        if resp.get(\"error\"):\n",
    "            print(f\"Chunk {idx} FAILED — error present.\")\n",
    "            print(\"error:\", resp[\"error\"])\n",
    "            # helpful debug: show the raw resp keys so you can adapt\n",
    "            print(\"full response dump keys:\", list(resp.keys()))\n",
    "            # show first few rows of the chunk for inspection\n",
    "            print(\"sample bad rows (first 5):\", chunk[:5])\n",
    "            # short backoff\n",
    "            time.sleep(1)\n",
    "            # you might want to continue or break depending on policy\n",
    "            # continue\n",
    "        else:\n",
    "            # success path — some clients put results under 'data'\n",
    "            data = resp.get(\"data\", resp)\n",
    "            # print number of rows upserted if available\n",
    "            try:\n",
    "                count = len(data) if isinstance(data, list) else (\"1\" if data else \"0\")\n",
    "            except Exception:\n",
    "                count = \"unknown\"\n",
    "            print(f\"Chunk {idx} OK — upserted rows: {count}\")\n",
    "\n",
    "    print(\"full_load finished.\")\n",
    "\n",
    "# USAGE:\n",
    "full_load(profiles)   # call this to run\n"
   ],
   "id": "1fd803f5b8a83e47",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 559\u001B[0m\n\u001B[1;32m    556\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfull_load finished.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    558\u001B[0m \u001B[38;5;66;03m# USAGE:\u001B[39;00m\n\u001B[0;32m--> 559\u001B[0m \u001B[43mfull_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprofiles\u001B[49m\u001B[43m)\u001B[49m   \u001B[38;5;66;03m# call this to run\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[25], line 526\u001B[0m, in \u001B[0;36mfull_load\u001B[0;34m(profiles, chunk_size, upsert)\u001B[0m\n\u001B[1;32m    520\u001B[0m profiles \u001B[38;5;241m=\u001B[39m make_world_profiles(n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10000\u001B[39m)\n\u001B[1;32m    522\u001B[0m \u001B[38;5;66;03m# save_profiles_csv(df, \"world_profiles.csv\")\u001B[39;00m\n\u001B[0;32m--> 526\u001B[0m profiles \u001B[38;5;241m=\u001B[39m [normalize_profile(\u001B[38;5;28mdict\u001B[39m(p)) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m profiles]\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mchunk_list\u001B[39m(lst, n):\n\u001B[1;32m    529\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(lst), n):\n",
      "Cell \u001B[0;32mIn[25], line 526\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    520\u001B[0m profiles \u001B[38;5;241m=\u001B[39m make_world_profiles(n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10000\u001B[39m)\n\u001B[1;32m    522\u001B[0m \u001B[38;5;66;03m# save_profiles_csv(df, \"world_profiles.csv\")\u001B[39;00m\n\u001B[0;32m--> 526\u001B[0m profiles \u001B[38;5;241m=\u001B[39m [normalize_profile(\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m profiles]\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mchunk_list\u001B[39m(lst, n):\n\u001B[1;32m    529\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(lst), n):\n",
      "\u001B[0;31mValueError\u001B[0m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9f02e74a0bc5f7f5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
